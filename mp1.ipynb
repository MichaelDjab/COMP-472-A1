{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da01f1b5",
   "metadata": {},
   "source": [
    "# COMP 472 Mini-Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79ab99",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47443d02",
   "metadata": {},
   "source": [
    "### 1.2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d462cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 1.1 - 1.2 Download & load dataset\n",
    "with open(\"goemotions.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "69ac5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "emotions = []\n",
    "sentiments = []\n",
    "\n",
    "for comment in data:\n",
    "    comments.append(comment[0])\n",
    "    emotions.append(comment[1])\n",
    "    sentiments.append(comment[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24569079",
   "metadata": {},
   "source": [
    "### 1.3. Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efa3c2e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#dictionary of emotions and frequency count\n",
    "emotions_count = Counter(emotions)\n",
    "\n",
    "#tuple of emotion labels, tuple of emotion frequency counts\n",
    "emotions_labels, emotions_count_values = zip(*emotions_count.items())\n",
    "\n",
    "#list of emotions_count_values indexes sorted by emotions_count_values in descending order (indexes that would sort in descending order)\n",
    "emotion_values_indexes_in_desc_order = np.argsort(emotions_count_values)[::-1]\n",
    "\n",
    "emotions_labels = np.array(emotions_labels)[emotion_values_indexes_in_desc_order]\n",
    "emotions_count_values = np.array(emotions_count_values)[emotion_values_indexes_in_desc_order]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.tick_params(labelsize=13)\n",
    "plt.title(\"Distribution of Emotions\", fontsize=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(emotions_labels, emotions_count_values)\n",
    "\n",
    "# adjustments\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "plt.savefig('Distribution_Emotions.pdf')  \n",
    "\n",
    "plt.show()\n",
    "\n",
    "#dictionary of sentiments and frequency count\n",
    "sentiments_count = Counter(sentiments)\n",
    "\n",
    "#tuple of sentiment labels, tuple of sentiment frequency counts\n",
    "sentiment_labels, sentiment_count_values = zip(*sentiments_count.items())\n",
    "\n",
    "#list of sentiment_count_values indexes sorted by sentiment_count_values in descending order (indexes that would sort in descending order)\n",
    "sentiment_values_indexes_in_desc_order = np.argsort(sentiment_count_values)[::-1]\n",
    "\n",
    "sentiment_labels = np.array(sentiment_labels)[sentiment_values_indexes_in_desc_order]\n",
    "sentiment_count_values = np.array(sentiment_count_values)[sentiment_values_indexes_in_desc_order]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.tick_params(labelsize=13)\n",
    "plt.title(\"Distribution of Sentiments\", fontsize=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(sentiment_labels, sentiment_count_values)\n",
    "\n",
    "# adjustments\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "plt.savefig('Distribution_Sentiments.pdf')  \n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9043c",
   "metadata": {},
   "source": [
    "## 2. Words as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954aca6c",
   "metadata": {},
   "source": [
    "### 2.1. Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "625fb290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in dataset: 30449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "#extract tokens/words and their frequency\n",
    "X = vectorizer.fit_transform(comments)\n",
    "\n",
    "#comments emotion classification\n",
    "y_emotions = np.array(emotions)\n",
    "#comments sentiment classification\n",
    "y_sentiments = np.array(sentiments)\n",
    "print(\"Number of tokens in dataset:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d97903",
   "metadata": {},
   "source": [
    "### 2.2. Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "971d2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split dataset for emotions classification\n",
    "X_train_emotions, X_test_emotions, y_train_emotions, y_test_emotions = train_test_split(X,y_emotions, test_size=0.2)\n",
    "\n",
    "#split dataset for sentiments classification\n",
    "X_train_sentiments, X_test_sentiments, y_train_sentiments, y_test_sentiments = train_test_split(X,y_sentiments, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624599d",
   "metadata": {},
   "source": [
    "### 2.3 \n",
    "#### Train and test the following classifiers, for both the emotion and the sentiment classification, using word frequency as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b50de817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to write confusion matrix, precision, recall and f1-measure to text file.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classification_performance(model_prediction, y_test, model_name, hyper_parameters):\n",
    "    conf_matrix = np.array2string(metrics.confusion_matrix(y_test, model_prediction))\n",
    "    class_report = classification_report(y_test, model_prediction, zero_division=0)\n",
    "    print(model_name + \" with \" + hyper_parameters + \":\\n\")\n",
    "    print(\"\\nConfusion Matrix:\\n\" + conf_matrix + \"\\n\")\n",
    "    print(\"\\nClassification Report:\\n\" + class_report + \"\\n\")\n",
    "    \n",
    "    with open(\"performance.txt\", \"a\") as file:\n",
    "        file.write(model_name + \" with \" + hyper_parameters + \":\\n\")\n",
    "        file.write(\"\\nConfusion Matrix:\\n\" + conf_matrix + \"\\n\")\n",
    "        file.write(\"\\nClassification Report:\\n\" + class_report + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d86e5",
   "metadata": {},
   "source": [
    "### 2.3.1. Base-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "91988c99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MNB emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 936   12    1   10   51    5    2    5    0    2    9    0    1    3\n",
      "     0   55    0    5   38    0  951   11    0    0    0    0    3    8]\n",
      " [  40  357    7   18   10    0    1    1    0    0    5    0    0    2\n",
      "     0    9    0   13   10    0  741    2    0    4    0    0    0    4]\n",
      " [   8    6  119   67    9    3    1    6    0    3   10    9    0    1\n",
      "     0    6    0    2    1    0  732    2    0    1    0    1    1    2]\n",
      " [  21   19   57  107   29    3    7    9    0   14   30    9    2    0\n",
      "     1   17    0    0    3    0 1336    5    0    2    0    0    2    3]\n",
      " [ 116   13    5   21  198    7   13    7    1    3   30    3    0    1\n",
      "     2   13    0    3   12    0 1756   12    0    4    0    0    8    1]\n",
      " [  15    2    4    6   18   45    1    3    0    2    6    0    0    1\n",
      "     0   14    0    6    6    0  608   14    0    1    0    0    5    0]\n",
      " [  11    6    1   11   17    0   47   30    0    2   19    0    0    0\n",
      "     0    5    0    0    2    0  798    0    0    2    0    0    0    4]\n",
      " [  21    3    1    8   14    3   14  110    1    2    6    0    0    4\n",
      "     0    7    0    1    2    0  964    0    0    1    0    0    3    7]\n",
      " [   7    2    1    7    9    1    1    0   17    2    3    0    0    0\n",
      "     0    0    0    2    7    0  351   23    0    1    0    0    1    1]\n",
      " [  18    3    8   28   21    5    4    2    0   33   20    5    2    0\n",
      "     0    6    0    1    3    0  805    4    0    4    0    2    6    5]\n",
      " [  26   13   10   37   37    0   13    3    0    4  122    6    0    1\n",
      "     3    3    0    1    3    0 1216    1    0    3    0    1    2    3]\n",
      " [  10    4   22   44   12    0    2    3    0    2   15   51    1    0\n",
      "     1    1    0    1    0    0  426    2    0    0    0    2    2    1]\n",
      " [   6    1    4    9    8    0    0    1    0    0    2    1    7    1\n",
      "     0    3    0    0    0    0  226    1    0    6    0    0    4    0]\n",
      " [  64    5    7    5   12    1    1    8    1    0    3    0    0   22\n",
      "     0    6    0   36    6    0  399    8    0    2    0    0    0   10]\n",
      " [  12    2    0    9    3    1    0    1    0    4    5    2    0    0\n",
      "     9    2    0    2    1    0  293    3    0    2    0    0    5    1]\n",
      " [  81    5    0    3    9    2    1    1    0    1    5    0    0    1\n",
      "     0  939    0   14    4    0  352   12    0    0    0    0    0    0]\n",
      " [   2    1    0    0    1    0    0    0    0    0    0    0    0    0\n",
      "     0    4    0    0    0    0   73    0    0    0    0    0    4    0]\n",
      " [  69   56    1    4   20    3    0    1    0    0    2    0    0    7\n",
      "     0   35    0   92   37    0  597    7    0    2    0    0    1    3]\n",
      " [  77    6    1    1    9    0    0    5    1    1    4    0    0    1\n",
      "     0    7    0   18  343    0  494    1    0    0    0    0    1    2]\n",
      " [   2    0    0    3    0    0    1    0    0    2    1    0    0    0\n",
      "     1    0    0    0    0    1  156    1    0    1    0    0    2    0]\n",
      " [ 298  104   85  140  252   43   40   88    4   52  168   18    4   20\n",
      "     4   68    1   36   64    0 9368   53    1   46    0    4   28   34]\n",
      " [  33    1    2    2   21    5    3    0    3    0    5    0    0    0\n",
      "     0   22    0    3    6    0  661  112    0    0    0    0    2    1]\n",
      " [  24    1    1    3    4    1    0    2    0    1    1    0    0    0\n",
      "     0    5    0    2    0    0   95    0    0    1    0    0    0    0]\n",
      " [  19    4    3    7   32    0    3    1    1    2   16    1    0    0\n",
      "     1    5    0    3    4    0  811    3    0   34    0    0    2    9]\n",
      " [  13    1    0    1    4    2    0    0    0    0    1    0    0    0\n",
      "     0   16    0    3    0    0  126    1    0    0    0    0    0    0]\n",
      " [   1    2    0    5    6    0    0    1    0    1    3    0    0    0\n",
      "     0   10    0    0    1    0  255    2    0    2    0   17    9    0]\n",
      " [  10    7    3   10    6    3    2    1    0   10    6    4    0    0\n",
      "     0    7    0    1    2    0  553    4    0    1    0    8   73    2]\n",
      " [  43    6    3    8   10    1    3   14    0    2    4    0    0    1\n",
      "     0    1    0    2    0    0  528    3    0    5    0    0    3   54]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.47      0.44      0.46      2108\n",
      "     amusement       0.56      0.29      0.38      1224\n",
      "         anger       0.34      0.12      0.18       990\n",
      "     annoyance       0.19      0.06      0.10      1676\n",
      "      approval       0.24      0.09      0.13      2229\n",
      "        caring       0.34      0.06      0.10       757\n",
      "     confusion       0.29      0.05      0.08       955\n",
      "     curiosity       0.36      0.09      0.15      1172\n",
      "        desire       0.59      0.04      0.07       436\n",
      "disappointment       0.23      0.03      0.06       985\n",
      "   disapproval       0.24      0.08      0.12      1508\n",
      "       disgust       0.47      0.08      0.14       602\n",
      " embarrassment       0.41      0.03      0.05       280\n",
      "    excitement       0.33      0.04      0.07       596\n",
      "          fear       0.41      0.03      0.05       357\n",
      "     gratitude       0.74      0.66      0.70      1430\n",
      "         grief       0.00      0.00      0.00        85\n",
      "           joy       0.37      0.10      0.16       937\n",
      "          love       0.62      0.35      0.45       972\n",
      "   nervousness       1.00      0.01      0.01       171\n",
      "       neutral       0.36      0.85      0.51     11023\n",
      "      optimism       0.39      0.13      0.19       882\n",
      "         pride       0.00      0.00      0.00       141\n",
      "   realization       0.27      0.04      0.06       961\n",
      "        relief       0.00      0.00      0.00       168\n",
      "       remorse       0.49      0.05      0.10       315\n",
      "       sadness       0.44      0.10      0.17       713\n",
      "      surprise       0.35      0.08      0.13       691\n",
      "\n",
      "      accuracy                           0.38     34364\n",
      "     macro avg       0.38      0.14      0.16     34364\n",
      "  weighted avg       0.38      0.38      0.31     34364\n",
      "\n",
      "\n",
      "Base-MNB sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 905  612 1364  814]\n",
      " [ 319 4027 2038 1211]\n",
      " [ 669 1954 5568 3005]\n",
      " [ 315  956 2252 8355]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.41      0.24      0.31      3695\n",
      "    negative       0.53      0.53      0.53      7595\n",
      "     neutral       0.50      0.50      0.50     11196\n",
      "    positive       0.62      0.70      0.66     11878\n",
      "\n",
      "    accuracy                           0.55     34364\n",
      "   macro avg       0.52      0.49      0.50     34364\n",
      "weighted avg       0.54      0.55      0.54     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Multinomial Naive Bayes Classifier for both emotions and sentiments.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_classifier_emotions = MultinomialNB()\n",
    "#train MNB emotions model\n",
    "mnb_model_emotions = mnb_classifier_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test MNB emotions model\n",
    "mnb_predict_emotions = mnb_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "mnb_classifier_sentiments = MultinomialNB()\n",
    "#train MNB sentiments model\n",
    "mnb_model_sentiments = mnb_classifier_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test MNB sentiments model\n",
    "mnb_predict_sentiments = mnb_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mnb_predict_emotions, y_test_emotions, \"Base-MNB emotions\", \"default parameters\")\n",
    "classification_performance(mnb_predict_sentiments, y_test_sentiments, \"Base-MNB sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bcf478",
   "metadata": {},
   "source": [
    "### 2.3.2. Base-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d6c6eca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-DT emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1207   42   14   34  136   22   10   29   15   14   14    9    5   41\n",
      "     5   58    0   34   78    1  272   20   14    9    4    0    2   19]\n",
      " [  57  677   19   48   28    9   20   14    8   10   20    8    6   25\n",
      "     1    4    1   34   15    0  189    6    0    4    5    3    6    7]\n",
      " [  20   29  349  153   39    9   17   16    5   19   39   36    3    4\n",
      "     3    4    1    2    3    2  219    4    1    3    1    1    5    3]\n",
      " [  49   56  229  359  112   34   43   31   14   72  107   43   21    6\n",
      "    11    9    2    6    9    3  406   10    0   13    1    3   20    7]\n",
      " [ 213   56   36  144  603   67   42   33   24   43   74   16    3   24\n",
      "    10   19    1   32   35    9  629   33    4   41    5    3   14   16]\n",
      " [  35   11   27   41   87  202   10    8   13   20   20    1    0    7\n",
      "     4   10    1   18    8    6  182   20    2    8    1    5    7    3]\n",
      " [  20   26   24   59   55   12  243  124    2   16   35    3    7   11\n",
      "     4    3    0    1    6    2  266    4    0   10    0    3    9   10]\n",
      " [  34   24   37   51   52   16  169  407    8   17   16    5    6   20\n",
      "     1    6    0    4    5    2  262    6    0    5    0    0    5   14]\n",
      " [  18    7    4   31   61    8   11   11  107   15    3    4    3   16\n",
      "     0    2    0    4   10    2   88   25    0    3    1    1    0    1]\n",
      " [  22   29   58  112   68   17   23   12   10  162   67   17   11    7\n",
      "    11    6    4    3    4    8  231   11    2   18    4   11   45   12]\n",
      " [  41   31   77  174  135   26   48   23   10   73  353   30    8    4\n",
      "     9    7    2   11    9    4  378    5    0   20    0    5   12   13]\n",
      " [  13   18   79  104   20    3   11    8    3   31   36  132   14    1\n",
      "     9    2    0    2    1    4  104    0    0    1    0    2    3    1]\n",
      " [   7   14   20   45   20    2   10    5    0   19    9   10   50    1\n",
      "     2    1    0    2    0    1   46    1    0    5    0    5    4    1]\n",
      " [  71   28   14   22   45    6    7   37    9    6    7    2    2  119\n",
      "     1    7    0   26   13    0  125   12    1    6    0    0    1   29]\n",
      " [   9   10   21   15   16    9    9    6    1   10   15    6    3    1\n",
      "   130    1    1    1    2    4   70    3    0    5    0    1    8    0]\n",
      " [ 122   17    4   18   43   17    7    6    5    4   13    1    1   14\n",
      "     2 1027    1   30    6    0   54   17    2    1    5    9    2    2]\n",
      " [   4    1    5    5    4    1    2    0    1    6    4    4    3    0\n",
      "     4    2    8    1    0    0   21    0    0    2    0    2    5    0]\n",
      " [ 103  123    6   26   52   16    5   13   10   10   17    2    2   50\n",
      "     2   36    1  226   70    0  128   14    5    6    3    0    2    9]\n",
      " [ 127   12    5   26   50   14    7    6   11    9   15    4    1   23\n",
      "     1    7    0   43  520    0   72    5    0    6    2    0    4    2]\n",
      " [   3    6    6   12   15   10    6    6    0   15    5    3    2    2\n",
      "    13    0    0    1    0   18   39    0    0    2    0    3    4    0]\n",
      " [ 502  331  406  687 1084  230  427  389  141  286  561  105   60  145\n",
      "    83   79   16  146  123   30 4749  100   17  127   11   21  102   65]\n",
      " [  75   12   14   30  108   40   18   12   46   17   21    3    4   20\n",
      "     4   20    1   14   10    1  222  173    1    3    2    5    2    4]\n",
      " [  26    5    3    5   20    5    2    1    0    0    2    1    1    4\n",
      "     0    3    1    6    1    0   47    1    6    1    0    0    0    0]\n",
      " [  30   31   37   63  124   11   27   17   14   28   54    7   10   10\n",
      "     6    6    4   15   10    2  347   12    2   67    3    6    9    9]\n",
      " [  17    6    3    7   25    8    1    1    2    6    2    0    0    2\n",
      "     1   13    0   16    2    0   31    1    1    3   17    0    3    0]\n",
      " [   5    7    7   25   10   12    5    4    0   21   10    5   12    2\n",
      "     1   15    4    1    0    1   37    0    0   10    0   98   23    0]\n",
      " [   8    9   24   55   43   30   11    5    6   70   33   10    7    2\n",
      "     9    8    8    5   10    3  156    2    2   12    1   41  139    4]\n",
      " [  59   31   24   41   30    5   22   41    3   22   14    8    6   24\n",
      "     9    5    1   11    0    0  172    7    1   12    2    1    2  138]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.42      0.57      0.48      2108\n",
      "     amusement       0.41      0.55      0.47      1224\n",
      "         anger       0.22      0.35      0.27       990\n",
      "     annoyance       0.15      0.21      0.18      1676\n",
      "      approval       0.20      0.27      0.23      2229\n",
      "        caring       0.24      0.27      0.25       757\n",
      "     confusion       0.20      0.25      0.22       955\n",
      "     curiosity       0.32      0.35      0.33      1172\n",
      "        desire       0.23      0.25      0.24       436\n",
      "disappointment       0.16      0.16      0.16       985\n",
      "   disapproval       0.23      0.23      0.23      1508\n",
      "       disgust       0.28      0.22      0.25       602\n",
      " embarrassment       0.20      0.18      0.19       280\n",
      "    excitement       0.20      0.20      0.20       596\n",
      "          fear       0.39      0.36      0.38       357\n",
      "     gratitude       0.76      0.72      0.74      1430\n",
      "         grief       0.14      0.09      0.11        85\n",
      "           joy       0.33      0.24      0.28       937\n",
      "          love       0.55      0.53      0.54       972\n",
      "   nervousness       0.17      0.11      0.13       171\n",
      "       neutral       0.50      0.43      0.46     11023\n",
      "      optimism       0.35      0.20      0.25       882\n",
      "         pride       0.10      0.04      0.06       141\n",
      "   realization       0.17      0.07      0.10       961\n",
      "        relief       0.25      0.10      0.14       168\n",
      "       remorse       0.43      0.31      0.36       315\n",
      "       sadness       0.32      0.19      0.24       713\n",
      "      surprise       0.37      0.20      0.26       691\n",
      "\n",
      "      accuracy                           0.36     34364\n",
      "     macro avg       0.30      0.27      0.28     34364\n",
      "  weighted avg       0.37      0.36      0.36     34364\n",
      "\n",
      "\n",
      "Base-DT sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1808  614  835  438]\n",
      " [ 833 4542 1507  713]\n",
      " [1657 2504 5254 1781]\n",
      " [ 882 1334 2602 7060]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.35      0.49      0.41      3695\n",
      "    negative       0.51      0.60      0.55      7595\n",
      "     neutral       0.52      0.47      0.49     11196\n",
      "    positive       0.71      0.59      0.65     11878\n",
      "\n",
      "    accuracy                           0.54     34364\n",
      "   macro avg       0.52      0.54      0.52     34364\n",
      "weighted avg       0.56      0.54      0.55     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Decision Tree Classifier for both emotions and sentiments.\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "dtc_emotions = tree.DecisionTreeClassifier()\n",
    "#train DTC emotions model\n",
    "dtc_model_emotions = dtc_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test DTC emotions model\n",
    "dtc_predict_emotions = dtc_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "dtc_sentiments = tree.DecisionTreeClassifier()\n",
    "#train DTC sentiments model\n",
    "dtc_model_sentiments = dtc_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test DTC sentiments model\n",
    "dtc_predict_sentiments = dtc_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(dtc_predict_emotions, y_test_emotions, \"Base-DT emotions\", \"default parameters\")\n",
    "classification_performance(dtc_predict_sentiments, y_test_sentiments, \"Base-DT sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a33885",
   "metadata": {},
   "source": [
    "### 2.3.3. Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c84d026e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MLP emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1049   21    5    3   15    5    4   11    5    0    8    0    1    4\n",
      "     0   31    0   25   87    0  786   17    0    1    0    0    4   26]\n",
      " [  30  707   12   13    2    0    4    3    5    0    5    1    1    1\n",
      "     0    6    0   20   15    0  377    6    0    1    0    1    1   13]\n",
      " [  10    9  232   21    7    5    0    4    7    2   15   12    0    0\n",
      "     2    6    0    3    3    0  637    5    0    1    0    2    5    2]\n",
      " [  20   47   96   50   11    7    3    6    3    6   23   21    0    0\n",
      "     6   15    0    5    9    0 1301    9    0    4    0    7   14   13]\n",
      " [ 133   33   11    6  131    8   12    4    1    1   18    1    0    5\n",
      "     7   10    0   25   32    0 1738   30    0    2    0    4   10    7]\n",
      " [  20    6    6    1    3   46    2    3    4    1    8    1    1    1\n",
      "     4    7    0   18   11    0  566   31    0    0    0    9    7    1]\n",
      " [  10   23   11    1    4    1   80   36    0    0   10    4    0    2\n",
      "     1    3    0    5    5    0  731    2    0    4    0    4    6   12]\n",
      " [  18   13   11    3    7    3   13  136    2    1    3    1    1    1\n",
      "     1    7    0    1    8    0  916    2    0    0    0    2    5   17]\n",
      " [  12    7    2    3    3    3    0    3   77    0    2    1    0    1\n",
      "     1    2    0    8   16    0  262   28    0    0    0    0    3    2]\n",
      " [  17   14    9   12   12    5    6    4    5   12   14   12    0    0\n",
      "     7    4    0    3    6    0  770   11    0    1    0   17   40    4]\n",
      " [  19   28   24   14   20    3   19    4    3    6   91    7    2    0\n",
      "     6    8    0    2   13    0 1194    9    0    3    0    7   13   13]\n",
      " [   5   11   58   15    0    0    0    0    0    0   13   86    1    0\n",
      "     7    1    0    1    1    0  392    3    0    0    0    1    6    1]\n",
      " [   2    7    6    2    0    1    1    1    0    1    1    6    7    0\n",
      "     4    1    0    0    0    0  219    2    0    1    0    7    7    4]\n",
      " [  71   13   10    1    5    1    1    5    2    0    0    0    0   38\n",
      "     1    7    0   41   14    0  347   10    0    1    0    1    1   26]\n",
      " [   3    7    5    1    2    0    0    0    1    0    2    2    0    0\n",
      "    89    0    0    1    6    0  229    1    0    0    0    1    5    2]\n",
      " [  89   14    1    1    2    6    2    1    1    0    1    1    0    0\n",
      "     2 1062    0   45   11    0  155   18    0    0    0   10    6    2]\n",
      " [   3    1    1    2    0    1    1    1    0    0    0    0    0    0\n",
      "     1    0    0    1    0    0   62    0    0    0    0    6    5    0]\n",
      " [  65  114    3    1    3    1    1    6    6    0    1    0    0    6\n",
      "     0   21    0  257   70    0  360   12    0    1    0    1    3    5]\n",
      " [  53   12    2    3    1    0    0    3    1    0    0    0    0    2\n",
      "     1    6    0   14  624    0  242    4    0    0    0    0    2    2]\n",
      " [   2    1    4    1    1    2    3    1    0    0    2    1    0    1\n",
      "     5    0    0    0    0    0  135    4    0    0    0    2    5    1]\n",
      " [ 233  227  128   40   79   42   39   97   24    9  100   23    2    8\n",
      "    23   57    0   61  140    0 9448   73    0   17    0   27   65   61]\n",
      " [  43   10    2    0   10    8    5    2   16    0    6    0    0    3\n",
      "     0   13    0   17   16    0  456  266    0    0    0    2    3    4]\n",
      " [  26    3    3    1    2    0    0    1    0    0    0    0    0    0\n",
      "     0    4    0    8    1    0   89    0    0    1    0    0    1    1]\n",
      " [  11   17    8    7   11    2    7    4    2    1    9    3    0    0\n",
      "     3    4    0    6   12    0  788    4    0   25    0    5    7   25]\n",
      " [  12    3    0    0    1    5    0    0    1    0    2    0    0    0\n",
      "     0   19    0   15    0    0  105    2    0    0    0    0    3    0]\n",
      " [   1    5    3    1    0    1    1    0    0    0    3    1    1    0\n",
      "     1    2    0    1    1    0  119    1    0    2    0  144   25    2]\n",
      " [   6    7    8    6    3    5    0    1    4    4    4    6    0    0\n",
      "     3    3    0    1    7    0  429    5    0    2    0   56  151    2]\n",
      " [  34    9   13    3    3    0    1   21    2    0    3    3    0    1\n",
      "     2    2    0    4    2    0  398    4    0    3    0    2    2  179]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.53      0.50      0.51      2108\n",
      "     amusement       0.52      0.58      0.55      1224\n",
      "         anger       0.34      0.23      0.28       990\n",
      "     annoyance       0.24      0.03      0.05      1676\n",
      "      approval       0.39      0.06      0.10      2229\n",
      "        caring       0.29      0.06      0.10       757\n",
      "     confusion       0.39      0.08      0.14       955\n",
      "     curiosity       0.38      0.12      0.18      1172\n",
      "        desire       0.45      0.18      0.25       436\n",
      "disappointment       0.27      0.01      0.02       985\n",
      "   disapproval       0.26      0.06      0.10      1508\n",
      "       disgust       0.45      0.14      0.22       602\n",
      " embarrassment       0.41      0.03      0.05       280\n",
      "    excitement       0.51      0.06      0.11       596\n",
      "          fear       0.50      0.25      0.33       357\n",
      "     gratitude       0.82      0.74      0.78      1430\n",
      "         grief       0.00      0.00      0.00        85\n",
      "           joy       0.44      0.27      0.34       937\n",
      "          love       0.56      0.64      0.60       972\n",
      "   nervousness       0.00      0.00      0.00       171\n",
      "       neutral       0.41      0.86      0.55     11023\n",
      "      optimism       0.48      0.30      0.37       882\n",
      "         pride       0.00      0.00      0.00       141\n",
      "   realization       0.36      0.03      0.05       961\n",
      "        relief       0.00      0.00      0.00       168\n",
      "       remorse       0.45      0.46      0.45       315\n",
      "       sadness       0.37      0.21      0.27       713\n",
      "      surprise       0.42      0.26      0.32       691\n",
      "\n",
      "      accuracy                           0.44     34364\n",
      "     macro avg       0.37      0.22      0.24     34364\n",
      "  weighted avg       0.41      0.44      0.36     34364\n",
      "\n",
      "\n",
      "Base-MLP sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 873  534 1765  523]\n",
      " [ 232 4041 2489  833]\n",
      " [ 500 1756 6925 2015]\n",
      " [ 265  912 2846 7855]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.47      0.24      0.31      3695\n",
      "    negative       0.56      0.53      0.54      7595\n",
      "     neutral       0.49      0.62      0.55     11196\n",
      "    positive       0.70      0.66      0.68     11878\n",
      "\n",
      "    accuracy                           0.57     34364\n",
      "   macro avg       0.55      0.51      0.52     34364\n",
      "weighted avg       0.58      0.57      0.57     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Perceptron Classifier for both emotions and sentiments.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_emotions = MLPClassifier(max_iter=1)\n",
    "#train MLP emotions model\n",
    "mlp_model_emotions = mlp_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test MLP emotions model\n",
    "mlp_predict_emotions = mlp_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "mlp_sentiments = MLPClassifier(max_iter=1)\n",
    "#train MLP sentiments model\n",
    "mlp_model_sentiments = mlp_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test MLP sentiments model\n",
    "mlp_predict_sentiments = mlp_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mlp_predict_emotions, y_test_emotions, \"Base-MLP emotions\", \"default parameters\")\n",
    "classification_performance(mlp_predict_sentiments, y_test_sentiments, \"Base-MLP sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d1186",
   "metadata": {},
   "source": [
    "### 2.3.4. Top-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "074a58a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-MNB emotions with alpha : [0, 0.5, 4, 5]:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1088   23    3   20   76   14    2   13    4    5   16    1    1    9\n",
      "     1   69    0   19   70    0  630   17    0    5    0    1    3   18]\n",
      " [  46  539   15   28   17    0    5    6    1    2   10    2    1    2\n",
      "     0   11    0   32   15    0  475    3    0    8    0    0    0    6]\n",
      " [  10    7  200   94   18    5    3    9    0   11   26   18    1    4\n",
      "     0    7    0    3    2    0  552    9    0    1    0    1    7    2]\n",
      " [  31   32  100  171   45   14   18   16    3   32   65   18    4    1\n",
      "     2   17    0    1    7    1 1057    9    0    8    0    2   15    7]\n",
      " [ 129   28   11   47  284   28   28   14   10   16   47    5    0    6\n",
      "     4   29    0   11   29    1 1433   30    0   22    0    0   14    3]\n",
      " [  19    4    2   12   26  117    2    4    3    5   13    0    0    2\n",
      "     1   19    0   10    8    0  460   32    0    5    1    3    9    0]\n",
      " [  13   12    4   19   28    3  113   65    0    8   29    2    1    4\n",
      "     1    8    0    0    4    0  611    6    0   11    0    0    1   12]\n",
      " [  23   12    7   17   25    9   27  184    4   10   19    0    0   10\n",
      "     0    9    0    1    4    0  788    5    0    3    0    0    5   10]\n",
      " [  10    6    2    8   12    5    2    4   39    6    4    4    0    3\n",
      "     0    2    0    3   11    1  276   32    0    1    0    1    2    2]\n",
      " [  20   11   12   46   26   12    9    5    0   71   42   10    3    5\n",
      "     4   10    0    5    6    0  631   10    0    7    0    6   24   10]\n",
      " [  32   24   23   58   57    9   35   11    0   19  223   14    0    3\n",
      "     6    5    0    4    3    0  938    8    0   11    0    1   10   14]\n",
      " [  12    6   34   60   16    2    4    6    0   10   28   93    5    1\n",
      "     4    1    0    3    2    0  292    5    0    3    0    4    8    3]\n",
      " [   6    5    7   19   10    3    5    4    0    7    5    3   17    1\n",
      "     1    3    0    1    0    0  159    1    0   11    0    3    8    1]\n",
      " [  75    8   10    7   15    1    2   13    3    1    4    0    0   50\n",
      "     0    9    0   45   14    0  304   12    1    2    0    0    0   20]\n",
      " [  19    2    2    9    8    3    4    3    1    5    5    3    1    0\n",
      "    42    2    0    2    1    1  229    4    0    2    0    0    7    2]\n",
      " [  91   10    0    5   19    5    3    3    1    2    6    0    0    2\n",
      "     1 1026    0   24    6    0  202   19    0    1    0    3    1    0]\n",
      " [   4    1    0    1    4    0    1    0    0    1    1    0    0    0\n",
      "     2    1    0    0    0    0   53    0    0    1    0    3   11    1]\n",
      " [  79   86    2    6   25    8    0    7    4    1    5    1    1   11\n",
      "     1   37    0  198   55    0  385   12    1    4    0    0    3    5]\n",
      " [  91    7    1    4   12    2    0    6    3    2    4    0    0    2\n",
      "     0    9    0   30  453    0  335    4    0    2    0    0    3    2]\n",
      " [   2    2    1    6    3    4    2    0    0    2    3    1    1    2\n",
      "     4    1    0    0    1    1  124    3    0    2    0    0    6    0]\n",
      " [ 367  182  153  236  408  106  149  185   31  106  313   50   10   52\n",
      "    24   99    2   74  118    2 7951  112    5  116    5   14   73   80]\n",
      " [  44    4    4    6   45   20   12    3    7    2    9    0    0    1\n",
      "     0   27    0   10    8    0  473  200    0    1    0    0    2    4]\n",
      " [  25    2    3    4    6    1    0    2    0    2    1    0    0    0\n",
      "     0    4    0    6    0    0   81    1    1    1    0    0    0    1]\n",
      " [  22   14    7   19   44    3   13    9    1   12   27    1    0    1\n",
      "     1    7    0    6    5    0  667    9    0   71    0    2    4   16]\n",
      " [  15    3    0    2    9    4    0    0    0    0    1    0    0    0\n",
      "     0   18    0   13    0    0   98    2    0    0    1    0    2    0]\n",
      " [   2    2    2    5    6    5    4    0    0    6    6    1    0    0\n",
      "     0   13    0    1    2    0  182    3    0    4    0   45   26    0]\n",
      " [   7    7    4   14   11   12    3    2    1   22   16    4    0    0\n",
      "     3   10    0    3    5    0  409    5    0    4    0   22  144    5]\n",
      " [  40    9   13   12   12    1    7   33    1    8   10    3    0    6\n",
      "     2    3    0    3    6    0  392    3    0   11    0    0    5  111]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.47      0.52      0.49      2108\n",
      "     amusement       0.51      0.44      0.47      1224\n",
      "         anger       0.32      0.20      0.25       990\n",
      "     annoyance       0.18      0.10      0.13      1676\n",
      "      approval       0.22      0.13      0.16      2229\n",
      "        caring       0.30      0.15      0.20       757\n",
      "     confusion       0.25      0.12      0.16       955\n",
      "     curiosity       0.30      0.16      0.21      1172\n",
      "        desire       0.33      0.09      0.14       436\n",
      "disappointment       0.19      0.07      0.10       985\n",
      "   disapproval       0.24      0.15      0.18      1508\n",
      "       disgust       0.40      0.15      0.22       602\n",
      " embarrassment       0.37      0.06      0.10       280\n",
      "    excitement       0.28      0.08      0.13       596\n",
      "          fear       0.40      0.12      0.18       357\n",
      "     gratitude       0.70      0.72      0.71      1430\n",
      "         grief       0.00      0.00      0.00        85\n",
      "           joy       0.39      0.21      0.27       937\n",
      "          love       0.54      0.47      0.50       972\n",
      "   nervousness       0.14      0.01      0.01       171\n",
      "       neutral       0.39      0.72      0.51     11023\n",
      "      optimism       0.36      0.23      0.28       882\n",
      "         pride       0.12      0.01      0.01       141\n",
      "   realization       0.22      0.07      0.11       961\n",
      "        relief       0.14      0.01      0.01       168\n",
      "       remorse       0.41      0.14      0.21       315\n",
      "       sadness       0.37      0.20      0.26       713\n",
      "      surprise       0.33      0.16      0.22       691\n",
      "\n",
      "      accuracy                           0.39     34364\n",
      "     macro avg       0.32      0.20      0.22     34364\n",
      "  weighted avg       0.36      0.39      0.35     34364\n",
      "\n",
      "\n",
      "Top-MNB sentiments with alpha : [0, 0.5, 4, 5]:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 717  590 1511  877]\n",
      " [ 205 3935 2179 1276]\n",
      " [ 487 1844 5789 3076]\n",
      " [ 219  888 2326 8445]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.44      0.19      0.27      3695\n",
      "    negative       0.54      0.52      0.53      7595\n",
      "     neutral       0.49      0.52      0.50     11196\n",
      "    positive       0.62      0.71      0.66     11878\n",
      "\n",
      "    accuracy                           0.55     34364\n",
      "   macro avg       0.52      0.49      0.49     34364\n",
      "weighted avg       0.54      0.55      0.54     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "search_space_MNB = {\n",
    "    \"alpha\" : [0, 0.5, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "gs_mnb_emotions = GridSearchCV(estimator=MultinomialNB(), param_grid = search_space_MNB)\n",
    "#train GS MNB emotions model\n",
    "gs_mnb_model_emotions = gs_mnb_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test GS MNB emotions model\n",
    "gs_mnb_predict_emotions = gs_mnb_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "\n",
    "gs_mnb_sentiments = GridSearchCV(estimator=MultinomialNB(), param_grid = search_space_MNB)\n",
    "#train GS MNB sentiments model\n",
    "gs_mnb_model_sentiments = gs_mnb_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test GS MNB sentiments model\n",
    "gs_mnb_predict_sentiments = gs_mnb_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(gs_mnb_predict_emotions, y_test_emotions, \"Top-MNB emotions\", \"alpha : [0, 0.5, 4, 5]\")\n",
    "classification_performance(gs_mnb_predict_sentiments, y_test_sentiments, \"Top-MNB sentiments\", \"alpha : [0, 0.5, 4, 5]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59625840",
   "metadata": {},
   "source": [
    "### 2.3.5. Top-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7ae34318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-DT emotions with criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  456    11     2     0     0     0     1     1     4     0     1     0\n",
      "      0     0     0    14     0    28    76     0  1494    18     0     0\n",
      "      0     2     0     0]\n",
      " [   25   396     0     1     0     0     0     0     2     0     1     0\n",
      "      1     0     0     4     0     7    10     0   766     7     0     0\n",
      "      0     4     0     0]\n",
      " [   16     2     0     0     0     0     0     0     4     0     0     0\n",
      "      1     0     0     5     0     3     5     0   948     3     0     0\n",
      "      0     3     0     0]\n",
      " [   27    20     0     1     1     1     0     0     4     0     2     1\n",
      "      0     0     0    12     0     7    11     0  1570    10     0     0\n",
      "      0     9     0     0]\n",
      " [   97    19     0     1     0     0     1     0     2     0     0     0\n",
      "      0     0     0     6     0    14    30     0  2032    23     0     0\n",
      "      0     4     0     0]\n",
      " [   25     3     0     0     0     2     0     0    11     0     0     0\n",
      "      0     0     0     3     0    19    10     0   649    24     0     0\n",
      "      0    11     0     0]\n",
      " [   10    12     0     0     1     0     1     0     0     0     0     0\n",
      "      0     0     0     3     0     9     6     0   909     0     0     0\n",
      "      0     4     0     0]\n",
      " [   17     8     0     0     0     0     1     0     4     0     0     0\n",
      "      0     0     0     6     0     1     9     0  1122     1     0     0\n",
      "      0     3     0     0]\n",
      " [   12     5     0     0     1     0     0     0    82     0     0     0\n",
      "      0     1     0     2     0     4    13     0   294    21     0     0\n",
      "      0     1     0     0]\n",
      " [   22    10     0     1     1     0     0     0     6     0     1     0\n",
      "      0     0     0     3     0     7     4     0   902     8     0     0\n",
      "      0    19     1     0]\n",
      " [   28    15     1     0     1     1     0     0     4     0     3     0\n",
      "      0     0     0     6     0     6    14     0  1417     7     0     0\n",
      "      0     5     0     0]\n",
      " [    8     5     0     0     0     0     0     0     1     0     0     1\n",
      "      0     0     0     0     0     2     0     0   579     3     0     0\n",
      "      0     3     0     0]\n",
      " [    0     1     0     0     0     0     0     0     1     0     0     0\n",
      "      0     0     0     1     0     1     1     0   266     2     0     0\n",
      "      0     7     0     0]\n",
      " [   22     4     0     0     0     0     0     0     2     0     0     0\n",
      "      0     0     0     0     0    41     8     0   513     6     0     0\n",
      "      0     0     0     0]\n",
      " [    4     6     0     0     0     0     0     0     1     0     1     0\n",
      "      0     0     0     1     0     1     4     0   337     1     0     0\n",
      "      0     1     0     0]\n",
      " [   63     8     1     5     0     0     2     0     1     0     6     0\n",
      "      0     0     0  1001     0    54    10     0   244    18     0     0\n",
      "      1    16     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1     0     0    75     0     0     0\n",
      "      0     7     0     0]\n",
      " [   63    21     0     0     0     0     0     0     6     0     1     0\n",
      "      0     0     0     6     0   195    54     0   578    12     0     0\n",
      "      0     1     0     0]\n",
      " [   12    11     0     2     3     1     1     0     3     0     1     0\n",
      "      0     3     0     6     0     7   579     0   340     3     0     0\n",
      "      0     0     0     0]\n",
      " [    2     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   163     2     0     0\n",
      "      0     3     0     0]\n",
      " [  204   113     0     1     3     2     2     1    28     0     2     0\n",
      "      2     1     0    37     0    49   131     0 10354    56     0     0\n",
      "      0    33     4     0]\n",
      " [   46     5     0     0     0     1     0     0    18     0     1     0\n",
      "      0     2     0     9     0    12    12     0   551   223     0     0\n",
      "      0     2     0     0]\n",
      " [    8     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0    10     0     0   120     0     0     0\n",
      "      0     0     0     0]\n",
      " [   13     7     1     0     0     0     1     0     3     0     0     0\n",
      "      0     0     0     3     0     4    15     0   908     1     0     0\n",
      "      0     5     0     0]\n",
      " [   13     2     0     0     0     0     0     0     1     0     0     0\n",
      "      0     0     0    11     0    16     0     0   119     0     0     0\n",
      "      6     0     0     0]\n",
      " [    1     4     0     1     0     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0     2     2     0   136     1     0     0\n",
      "      0   164     3     0]\n",
      " [   11     4     0     0     0     0     0     0     6     0     0     0\n",
      "      0     0     0     2     0     2     5     0   606     8     0     0\n",
      "      0    66     3     0]\n",
      " [   11     4     0     0     0     0     0     1     3     0     0     0\n",
      "      0     0     0     1     0     6     1     0   660     2     0     0\n",
      "      0     2     0     0]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.37      0.22      0.27      2108\n",
      "     amusement       0.57      0.32      0.41      1224\n",
      "         anger       0.00      0.00      0.00       990\n",
      "     annoyance       0.08      0.00      0.00      1676\n",
      "      approval       0.00      0.00      0.00      2229\n",
      "        caring       0.22      0.00      0.01       757\n",
      "     confusion       0.10      0.00      0.00       955\n",
      "     curiosity       0.00      0.00      0.00      1172\n",
      "        desire       0.42      0.19      0.26       436\n",
      "disappointment       0.00      0.00      0.00       985\n",
      "   disapproval       0.15      0.00      0.00      1508\n",
      "       disgust       0.50      0.00      0.00       602\n",
      " embarrassment       0.00      0.00      0.00       280\n",
      "    excitement       0.00      0.00      0.00       596\n",
      "          fear       0.00      0.00      0.00       357\n",
      "     gratitude       0.88      0.70      0.78      1430\n",
      "         grief       0.00      0.00      0.00        85\n",
      "           joy       0.38      0.21      0.27       937\n",
      "          love       0.57      0.60      0.58       972\n",
      "   nervousness       0.00      0.00      0.00       171\n",
      "       neutral       0.36      0.94      0.52     11023\n",
      "      optimism       0.48      0.25      0.33       882\n",
      "         pride       0.00      0.00      0.00       141\n",
      "   realization       0.00      0.00      0.00       961\n",
      "        relief       0.86      0.04      0.07       168\n",
      "       remorse       0.44      0.52      0.48       315\n",
      "       sadness       0.27      0.00      0.01       713\n",
      "      surprise       0.00      0.00      0.00       691\n",
      "\n",
      "      accuracy                           0.39     34364\n",
      "     macro avg       0.24      0.14      0.14     34364\n",
      "  weighted avg       0.28      0.39      0.27     34364\n",
      "\n",
      "\n",
      "Top-DT sentiments with criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   34    27  3478   156]\n",
      " [    5   356  6901   333]\n",
      " [   12    59 10511   614]\n",
      " [   19    94  7794  3971]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.49      0.01      0.02      3695\n",
      "    negative       0.66      0.05      0.09      7595\n",
      "     neutral       0.37      0.94      0.53     11196\n",
      "    positive       0.78      0.33      0.47     11878\n",
      "\n",
      "    accuracy                           0.43     34364\n",
      "   macro avg       0.57      0.33      0.28     34364\n",
      "weighted avg       0.59      0.43      0.35     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "search_space_DT = {\n",
    "    \"criterion\" : np.array([\"entropy\"]),\n",
    "    \"max_depth\" : np.array([10, 11]),\n",
    "    \"min_samples_split\" : np.array([5, 10, 15])\n",
    "}\n",
    "\n",
    "gs_dt_emotions = GridSearchCV(tree.DecisionTreeClassifier(), search_space_DT)\n",
    "#train GS DT emotions model\n",
    "gs_dt_model_emotions = gs_dt_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test GS DT emotions model\n",
    "gs_dt_predict_emotions = gs_dt_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "gs_dt_sentiments = GridSearchCV(tree.DecisionTreeClassifier(), search_space_DT)\n",
    "#train GS DT model sentiments\n",
    "gs_dt_model_sentiments = gs_dt_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test GS DT model sentiments\n",
    "gs_dt_predict_sentiments = gs_dt_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(gs_dt_predict_emotions, y_test_emotions, \"Top-DT emotions\", \"criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15\")\n",
    "classification_performance(gs_dt_predict_sentiments, y_test_sentiments, \"Top-DT sentiments\", \"criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4218b8e",
   "metadata": {},
   "source": [
    "### 2.3.6. Top-MLP (3pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a3cf21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-MLP emotions with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  456    11     2     0     0     0     1     1     4     0     1     0\n",
      "      0     0     0    14     0    28    76     0  1494    18     0     0\n",
      "      0     2     0     0]\n",
      " [   25   396     0     1     0     0     0     0     2     0     1     0\n",
      "      1     0     0     4     0     7    10     0   766     7     0     0\n",
      "      0     4     0     0]\n",
      " [   16     2     0     0     0     0     0     0     4     0     0     0\n",
      "      1     0     0     5     0     3     5     0   948     3     0     0\n",
      "      0     3     0     0]\n",
      " [   27    20     0     1     1     1     0     0     4     0     2     1\n",
      "      0     0     0    12     0     7    11     0  1570    10     0     0\n",
      "      0     9     0     0]\n",
      " [   97    19     0     1     0     0     1     0     2     0     0     0\n",
      "      0     0     0     6     0    14    30     0  2032    23     0     0\n",
      "      0     4     0     0]\n",
      " [   25     3     0     0     0     2     0     0    11     0     0     0\n",
      "      0     0     0     3     0    19    10     0   649    24     0     0\n",
      "      0    11     0     0]\n",
      " [   10    12     0     0     1     0     1     0     0     0     0     0\n",
      "      0     0     0     3     0     9     6     0   909     0     0     0\n",
      "      0     4     0     0]\n",
      " [   17     8     0     0     0     0     1     0     4     0     0     0\n",
      "      0     0     0     6     0     1     9     0  1122     1     0     0\n",
      "      0     3     0     0]\n",
      " [   12     5     0     0     1     0     0     0    82     0     0     0\n",
      "      0     1     0     2     0     4    13     0   294    21     0     0\n",
      "      0     1     0     0]\n",
      " [   22    10     0     1     1     0     0     0     6     0     1     0\n",
      "      0     0     0     3     0     7     4     0   902     8     0     0\n",
      "      0    19     1     0]\n",
      " [   28    15     1     0     1     1     0     0     4     0     3     0\n",
      "      0     0     0     6     0     6    14     0  1417     7     0     0\n",
      "      0     5     0     0]\n",
      " [    8     5     0     0     0     0     0     0     1     0     0     1\n",
      "      0     0     0     0     0     2     0     0   579     3     0     0\n",
      "      0     3     0     0]\n",
      " [    0     1     0     0     0     0     0     0     1     0     0     0\n",
      "      0     0     0     1     0     1     1     0   266     2     0     0\n",
      "      0     7     0     0]\n",
      " [   22     4     0     0     0     0     0     0     2     0     0     0\n",
      "      0     0     0     0     0    41     8     0   513     6     0     0\n",
      "      0     0     0     0]\n",
      " [    4     6     0     0     0     0     0     0     1     0     1     0\n",
      "      0     0     0     1     0     1     4     0   337     1     0     0\n",
      "      0     1     0     0]\n",
      " [   63     8     1     5     0     0     2     0     1     0     6     0\n",
      "      0     0     0  1001     0    54    10     0   244    18     0     0\n",
      "      1    16     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1     0     0    75     0     0     0\n",
      "      0     7     0     0]\n",
      " [   63    21     0     0     0     0     0     0     6     0     1     0\n",
      "      0     0     0     6     0   195    54     0   578    12     0     0\n",
      "      0     1     0     0]\n",
      " [   12    11     0     2     3     1     1     0     3     0     1     0\n",
      "      0     3     0     6     0     7   579     0   340     3     0     0\n",
      "      0     0     0     0]\n",
      " [    2     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   163     2     0     0\n",
      "      0     3     0     0]\n",
      " [  204   113     0     1     3     2     2     1    28     0     2     0\n",
      "      2     1     0    37     0    49   131     0 10354    56     0     0\n",
      "      0    33     4     0]\n",
      " [   46     5     0     0     0     1     0     0    18     0     1     0\n",
      "      0     2     0     9     0    12    12     0   551   223     0     0\n",
      "      0     2     0     0]\n",
      " [    8     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0    10     0     0   120     0     0     0\n",
      "      0     0     0     0]\n",
      " [   13     7     1     0     0     0     1     0     3     0     0     0\n",
      "      0     0     0     3     0     4    15     0   908     1     0     0\n",
      "      0     5     0     0]\n",
      " [   13     2     0     0     0     0     0     0     1     0     0     0\n",
      "      0     0     0    11     0    16     0     0   119     0     0     0\n",
      "      6     0     0     0]\n",
      " [    1     4     0     1     0     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0     2     2     0   136     1     0     0\n",
      "      0   164     3     0]\n",
      " [   11     4     0     0     0     0     0     0     6     0     0     0\n",
      "      0     0     0     2     0     2     5     0   606     8     0     0\n",
      "      0    66     3     0]\n",
      " [   11     4     0     0     0     0     0     1     3     0     0     0\n",
      "      0     0     0     1     0     6     1     0   660     2     0     0\n",
      "      0     2     0     0]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.37      0.22      0.27      2108\n",
      "     amusement       0.57      0.32      0.41      1224\n",
      "         anger       0.00      0.00      0.00       990\n",
      "     annoyance       0.08      0.00      0.00      1676\n",
      "      approval       0.00      0.00      0.00      2229\n",
      "        caring       0.22      0.00      0.01       757\n",
      "     confusion       0.10      0.00      0.00       955\n",
      "     curiosity       0.00      0.00      0.00      1172\n",
      "        desire       0.42      0.19      0.26       436\n",
      "disappointment       0.00      0.00      0.00       985\n",
      "   disapproval       0.15      0.00      0.00      1508\n",
      "       disgust       0.50      0.00      0.00       602\n",
      " embarrassment       0.00      0.00      0.00       280\n",
      "    excitement       0.00      0.00      0.00       596\n",
      "          fear       0.00      0.00      0.00       357\n",
      "     gratitude       0.88      0.70      0.78      1430\n",
      "         grief       0.00      0.00      0.00        85\n",
      "           joy       0.38      0.21      0.27       937\n",
      "          love       0.57      0.60      0.58       972\n",
      "   nervousness       0.00      0.00      0.00       171\n",
      "       neutral       0.36      0.94      0.52     11023\n",
      "      optimism       0.48      0.25      0.33       882\n",
      "         pride       0.00      0.00      0.00       141\n",
      "   realization       0.00      0.00      0.00       961\n",
      "        relief       0.86      0.04      0.07       168\n",
      "       remorse       0.44      0.52      0.48       315\n",
      "       sadness       0.27      0.00      0.01       713\n",
      "      surprise       0.00      0.00      0.00       691\n",
      "\n",
      "      accuracy                           0.39     34364\n",
      "     macro avg       0.24      0.14      0.14     34364\n",
      "  weighted avg       0.28      0.39      0.27     34364\n",
      "\n",
      "\n",
      "Top-MLP sentiments with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   34    27  3478   156]\n",
      " [    5   356  6901   333]\n",
      " [   12    59 10511   614]\n",
      " [   19    94  7794  3971]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.49      0.01      0.02      3695\n",
      "    negative       0.66      0.05      0.09      7595\n",
      "     neutral       0.37      0.94      0.53     11196\n",
      "    positive       0.78      0.33      0.47     11878\n",
      "\n",
      "    accuracy                           0.43     34364\n",
      "   macro avg       0.57      0.33      0.28     34364\n",
      "weighted avg       0.59      0.43      0.35     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Top-MLP\n",
    "search_space_Top_MLP = {\n",
    "    'activation' : np.array(['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'hidden_layer_sizes' : [(30, 50), (10, 10, 10)],\n",
    "    'solver' : ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "gs_mlp_model_emotions = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP)\n",
    "\n",
    "# Emotions:\n",
    "#train GS MLP emotions model\n",
    "gs_mlp_model_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "\n",
    "#test GS MLP emotions model\n",
    "gs_mlp_predict_emotions = gs_dt_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "# Sentiments:\n",
    "gs_mlp_model_sentiments = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP)\n",
    "\n",
    "#train GS MLP emotions model\n",
    "gs_mlp_model_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "\n",
    "#test GS MLP emotions model\n",
    "gs_mlp_predict_sentiments = gs_dt_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "classification_performance(gs_mlp_predict_emotions, y_test_emotions, \"Top-MLP emotions\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")\n",
    "classification_performance(gs_mlp_predict_sentiments, y_test_sentiments, \"Top-MLP sentiments\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3bc0a",
   "metadata": {},
   "source": [
    "### 2.4 (5pts)\n",
    "#### In each part of 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3617e9",
   "metadata": {},
   "source": [
    "### 2.5 (7.5pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2fc5f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset for emotions classification\n",
    "X_train_emotions, X_test_emotions, y_train_emotions, y_test_emotions = train_test_split(X,y_emotions, test_size=0.7)\n",
    "\n",
    "#split dataset for sentiments classification\n",
    "X_train_sentiments, X_test_sentiments, y_train_sentiments, y_test_sentiments = train_test_split(X,y_sentiments, test_size=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b50e39",
   "metadata": {},
   "source": [
    "### 2.5.1 Base-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "39586a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MNB emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1862    19     2     9    68     5     0     4     0     0     9     0\n",
      "      0     1     0    86     0    16    38     0  5151    10     0     3\n",
      "      0     0     2     8]\n",
      " [   66   473     3    15    20     0     0     3     0     0     3     0\n",
      "      0     2     0    14     0    11     9     0  3592     0     0     0\n",
      "      0     0     1     3]\n",
      " [   22    12   122    86    19     3     1     4     0     1    18     3\n",
      "      0     0     0    12     0     1     1     0  3380     3     0     1\n",
      "      0     1     0     4]\n",
      " [   40    23    29    98    42     1     3     2     0     1    20     6\n",
      "      0     1     2    16     0     1     3     0  5635     1     0     1\n",
      "      0     0     4     6]\n",
      " [  168    18     2    29   271     2     5     6     0     3    30     1\n",
      "      0     4     1    17     0     3    16     0  7205     7     0    11\n",
      "      0     0     3     2]\n",
      " [   32     0     2     1    16    16     1     1     0     2     5     0\n",
      "      0     0     0    20     0     4     2     0  2387    15     0     1\n",
      "      0     1     0     0]\n",
      " [    8     5     2    10    19     1    22    27     0     0    14     0\n",
      "      0     0     0     7     0     0     0     0  3315     1     0     2\n",
      "      0     0     0     0]\n",
      " [   29     3     4     7    40     3     2    84     0     0     2     0\n",
      "      0     2     0    12     0     1     1     0  3944     0     0     3\n",
      "      0     0     0     3]\n",
      " [   10     8     0     3    19     0     1     2     3     1     3     0\n",
      "      0     2     0     5     0     1     1     0  1457    11     0     0\n",
      "      0     0     0     0]\n",
      " [   24     5     1    26    24     0     1     0     0    17    13     1\n",
      "      0     0     0     6     0     0     1     0  3117     2     0     6\n",
      "      0     1     7     0]\n",
      " [   28    15     7    28    57     1     6     6     0     3   108     2\n",
      "      0     2     1    11     0     1     3     0  5027     3     0     3\n",
      "      0     0     1     0]\n",
      " [   13     2    25    48    20     0     1     0     0     3    13    28\n",
      "      0     0     0     2     0     0     2     0  1870     1     0     1\n",
      "      0     1     4     1]\n",
      " [   10     0     4     5     9     0     0     0     0     0     3     1\n",
      "      1     0     0     1     0     0     3     0   954     0     0     1\n",
      "      0     1     1     1]\n",
      " [  112    10     4    12    26     0     2    10     0     2     1     1\n",
      "      0    17     0    17     0    64     6     0  1819     3     0     3\n",
      "      0     0     0     5]\n",
      " [   12     4     0     1     9     0     1     0     0     2     9     1\n",
      "      0     1     2     0     0     0     0     0  1161     4     0     0\n",
      "      0     0     0     7]\n",
      " [  180     5     0     5    11     5     1     0     0     0     5     0\n",
      "      0     1     0  2344     0    27     1     0  2351     2     0     1\n",
      "      0     4     0     0]\n",
      " [    0     0     0     1     1     0     0     0     0     0     0     0\n",
      "      0     0     0     5     0     0     0     0   225     0     0     0\n",
      "      0     0     2     0]\n",
      " [  153    71     4     5    23     1     1     0     0     1     5     0\n",
      "      0     3     0    38     0   108    31     0  2648     4     0     0\n",
      "      0     0     0     1]\n",
      " [  134     7     2     3    16     0     0     0     0     0     3     0\n",
      "      0     0     0     6     0     8   472     0  2830     3     0     0\n",
      "      0     0     1     1]\n",
      " [    1     1     0     3     3     1     2     0     0     2     4     0\n",
      "      0     0     0     2     0     0     0     0   520     0     0     0\n",
      "      0     0     1     1]\n",
      " [  523   149    79   206   473    28    26    75     2    35   186    17\n",
      "      0    26     4   152     0    49    97     0 36687    41     0    44\n",
      "      0     2    22    31]\n",
      " [   81     0     0     2    30     5     0     1     1     0     1     0\n",
      "      0     0     0    21     0     3     6     0  2939    57     0     0\n",
      "      0     0     0     0]\n",
      " [   31     1     0     0     6     0     0     0     0     1     2     0\n",
      "      0     1     0     3     0     0     0     0   417     0     0     0\n",
      "      0     0     0     1]\n",
      " [   24     4     2    12    38     1     2     3     0     1    12     0\n",
      "      0     0     0     4     0     1     2     0  3131     0     0    18\n",
      "      0     0     0     0]\n",
      " [   14     0     0     1     1     0     0     0     0     0     1     0\n",
      "      0     0     0    14     0     3     0     0   506     0     0     1\n",
      "      0     0     0     0]\n",
      " [    1     1     0     3     0     0     1     0     0     3     1     0\n",
      "      0     0     0    26     0     0     2     0   981     1     0     2\n",
      "      0    17     8     1]\n",
      " [    8     4     2    14    17     0     1     0     0    10    15     1\n",
      "      0     1     0     6     0     0     1     0  2559     2     0     1\n",
      "      0     2    43     2]\n",
      " [   74     7     8     7    12     0     5     5     0     0    10     1\n",
      "      0     1     1     5     0     6     2     0  2213     1     0     4\n",
      "      0     0     1    43]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.51      0.26      0.34      7293\n",
      "     amusement       0.56      0.11      0.19      4215\n",
      "         anger       0.40      0.03      0.06      3694\n",
      "     annoyance       0.15      0.02      0.03      5935\n",
      "      approval       0.21      0.03      0.06      7804\n",
      "        caring       0.22      0.01      0.01      2506\n",
      "     confusion       0.26      0.01      0.01      3433\n",
      "     curiosity       0.36      0.02      0.04      4140\n",
      "        desire       0.50      0.00      0.00      1527\n",
      "disappointment       0.19      0.01      0.01      3252\n",
      "   disapproval       0.22      0.02      0.04      5313\n",
      "       disgust       0.44      0.01      0.03      2035\n",
      " embarrassment       1.00      0.00      0.00       995\n",
      "    excitement       0.26      0.01      0.02      2114\n",
      "          fear       0.18      0.00      0.00      1214\n",
      "     gratitude       0.82      0.47      0.60      4943\n",
      "         grief       0.00      0.00      0.00       234\n",
      "           joy       0.35      0.03      0.06      3097\n",
      "          love       0.67      0.14      0.23      3486\n",
      "   nervousness       0.00      0.00      0.00       541\n",
      "       neutral       0.34      0.94      0.50     38954\n",
      "      optimism       0.33      0.02      0.03      3147\n",
      "         pride       0.00      0.00      0.00       463\n",
      "   realization       0.17      0.01      0.01      3255\n",
      "        relief       0.00      0.00      0.00       541\n",
      "       remorse       0.57      0.02      0.03      1048\n",
      "       sadness       0.43      0.02      0.03      2689\n",
      "      surprise       0.36      0.02      0.03      2406\n",
      "\n",
      "      accuracy                           0.36    120274\n",
      "     macro avg       0.34      0.08      0.08    120274\n",
      "  weighted avg       0.36      0.36      0.24    120274\n",
      "\n",
      "\n",
      "Base-MNB sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1530  2053  5895  3817]\n",
      " [  540 12018  8718  5700]\n",
      " [ 1191  6191 19187 12244]\n",
      " [  495  2903  8384 29408]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.41      0.12      0.18     13295\n",
      "    negative       0.52      0.45      0.48     26976\n",
      "     neutral       0.45      0.49      0.47     38813\n",
      "    positive       0.57      0.71      0.64     41190\n",
      "\n",
      "    accuracy                           0.52    120274\n",
      "   macro avg       0.49      0.44      0.44    120274\n",
      "weighted avg       0.50      0.52      0.50    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Multinomial Naive Bayes Classifier for both emotions and sentiments.\n",
    "\n",
    "# Emotions:\n",
    "mnb_classifier_emotions = MultinomialNB()\n",
    "#train MNB emotions model\n",
    "mnb_model_emotions = mnb_classifier_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test MNB emotions model\n",
    "mnb_predict_emotions = mnb_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "# Sentiments\n",
    "mnb_classifier_sentiments = MultinomialNB()\n",
    "#train MNB sentiments model\n",
    "mnb_model_sentiments = mnb_classifier_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test MNB sentiments model\n",
    "mnb_predict_sentiments = mnb_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mnb_predict_emotions, y_test_emotions, \"Base-MNB emotions\", \"default parameters\")\n",
    "classification_performance(mnb_predict_sentiments, y_test_sentiments, \"Base-MNB sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acb871",
   "metadata": {},
   "source": [
    "### 2.5.2 Base-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "94b8c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-DT emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3337   157    69   119   466    79    69    84    55    52    76    24\n",
      "     15   175    19   257     8   169   298    10  1403   111    42    63\n",
      "     17     6    22    91]\n",
      " [  199  2096    56   124   131    32    43    48    11    36    73    34\n",
      "     20    56    29    40     0   225    32     4   768    40     1    43\n",
      "      3     8    26    37]\n",
      " [   76    94   880   459   152    44    74    79    25   113   158   126\n",
      "     25    26    38    23     4    21    33     7  1088    34     3    25\n",
      "      4     6    36    41]\n",
      " [  178   205   495   792   363   115   163   165    42   203   388   183\n",
      "     60    57    63    55     6    71    65    29  1885    62     8    94\n",
      "      6    28    88    66]\n",
      " [  569   193   114   368  1409   186   175   130    91   173   313    58\n",
      "     42   115    42    87    11   125   130    24  2909   173    29   162\n",
      "     27    24    58    67]\n",
      " [  125    43    43    99   220   417    40    39    34    68    90     8\n",
      "     13    21    20    51     6    64    49    28   773   113     2    31\n",
      "     19    25    54    11]\n",
      " [   73    71    67   159   183    33   666   350    26    68   139    21\n",
      "     26    31    18    10     7    23    36     9  1211    31     8    74\n",
      "      5    16    20    52]\n",
      " [  106    71    72   184   189    45   417  1019    35    59    90    28\n",
      "     18    56    15    20     3    38    50    10  1413    44     4    43\n",
      "      1    10    19    81]\n",
      " [   65    38    25    45   115    24    22    42   312    31    32     4\n",
      "      9    31    12    18     1    30    51     2   451   113     1    19\n",
      "      0     5    19    10]\n",
      " [   84    73   120   254   204    51    77    68    29   345   236    66\n",
      "     47    27    31    26    12    35    21    19  1026    50     8    62\n",
      "      6    36   196    43]\n",
      " [  154   114   220   441   349    58   157   103    49   209   920   103\n",
      "     53    26    52    33     2    48    46    30  1851    45     6    78\n",
      "      4    33    81    48]\n",
      " [   39    45   206   220   103    11    43    30    16    93   106   325\n",
      "     44    11    47     7    10    15     7     8   547    20     4    16\n",
      "      2     5    40    15]\n",
      " [   26    22    43    91    67     6    28    22     5    39    53    31\n",
      "    138     9    15     5     7     9     6    10   276    13     1    16\n",
      "      0    20    25    12]\n",
      " [  243    84    40    54   106    21    29    79    38    30    38     7\n",
      "     13   339     7    42     2   108    57     5   587    29    11    28\n",
      "      4     3    10   100]\n",
      " [   37    24    33    51    66    30    34    20     5    31    49    26\n",
      "     12     5   331     2     3     7     6    18   328    19     6    18\n",
      "      0     4    27    22]\n",
      " [  310    45     9    63   116    57    28    21    13    26    24     3\n",
      "     13    56     2  3547     3    73    29     5   308    63     6    18\n",
      "     27    35    27    16]\n",
      " [    8     4     8    11    15     3     6     1     2    14     8     5\n",
      "      4     2     4     5    19     4     5     0    68     3     1     8\n",
      "      0     3    22     1]\n",
      " [  321   363    24    60   184    53    34    25    32    36    33     7\n",
      "      8   154    15   111     3   643   188     2   602    54    24    30\n",
      "     41     3    15    32]\n",
      " [  345    70    16    51   153    57    32    25    30    27    32     7\n",
      "     11    36     3    50     4    96  1875     0   492    28     1    20\n",
      "      1     2    13     9]\n",
      " [    7     5    20    31    33    16    16    14     6    40    30     6\n",
      "      3     8    28     1     1     6     1    46   175    12     0    13\n",
      "      0     3    19     1]\n",
      " [ 1632  1049  1062  1842  3012   721  1135  1186   385   963  1804   415\n",
      "    259   498   240   289    62   543   564   150 18620   644    96   709\n",
      "     85   109   448   432]\n",
      " [  224    48    25   113   269   139    51    45   126    52    86    17\n",
      "     15    50    12    67     6    74    38     6   837   737    15    39\n",
      "      8    10    13    25]\n",
      " [   75     5     9    13    30     9    11     5     2    13    14     3\n",
      "      1     8     1     8     1    18     5     0   176    14    21     6\n",
      "      6     1     7     1]\n",
      " [  120    90    81   165   310    65    98    73    42    92   193    33\n",
      "     26    32    28    18     6    43    38    15  1233    59     8   257\n",
      "     10    18    37    65]\n",
      " [   62    14     7    20    54    19    10     8     4    12    14     2\n",
      "      6     5     1    37     2    43     4     5   143    17     2     7\n",
      "     36     0     4     3]\n",
      " [   14     5    17    46    39    34    16     8    10    56    45    14\n",
      "     22     3     2    45    18     5     9     5   189    17     1    16\n",
      "      0   293   115     4]\n",
      " [   54    41    75   137   116    62    32    30    20   189   137    48\n",
      "     31    15    22    40    22    30    24    22   715    32     4    37\n",
      "      9   120   614    11]\n",
      " [  170    63    65   108   118    22    81    93    12    58   104    21\n",
      "     15    70    20    16     2    38    21     8   723    13     3    45\n",
      "      3    14    17   483]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.39      0.46      0.42      7293\n",
      "     amusement       0.41      0.50      0.45      4215\n",
      "         anger       0.23      0.24      0.23      3694\n",
      "     annoyance       0.13      0.13      0.13      5935\n",
      "      approval       0.16      0.18      0.17      7804\n",
      "        caring       0.17      0.17      0.17      2506\n",
      "     confusion       0.19      0.19      0.19      3433\n",
      "     curiosity       0.27      0.25      0.26      4140\n",
      "        desire       0.21      0.20      0.21      1527\n",
      "disappointment       0.11      0.11      0.11      3252\n",
      "   disapproval       0.17      0.17      0.17      5313\n",
      "       disgust       0.20      0.16      0.18      2035\n",
      " embarrassment       0.15      0.14      0.14       995\n",
      "    excitement       0.18      0.16      0.17      2114\n",
      "          fear       0.30      0.27      0.28      1214\n",
      "     gratitude       0.72      0.72      0.72      4943\n",
      "         grief       0.08      0.08      0.08       234\n",
      "           joy       0.25      0.21      0.23      3097\n",
      "          love       0.51      0.54      0.52      3486\n",
      "   nervousness       0.10      0.09      0.09       541\n",
      "       neutral       0.46      0.48      0.47     38954\n",
      "      optimism       0.28      0.23      0.26      3147\n",
      "         pride       0.07      0.05      0.05       463\n",
      "   realization       0.13      0.08      0.10      3255\n",
      "        relief       0.11      0.07      0.08       541\n",
      "       remorse       0.35      0.28      0.31      1048\n",
      "       sadness       0.30      0.23      0.26      2689\n",
      "      surprise       0.27      0.20      0.23      2406\n",
      "\n",
      "      accuracy                           0.34    120274\n",
      "     macro avg       0.25      0.23      0.24    120274\n",
      "  weighted avg       0.33      0.34      0.33    120274\n",
      "\n",
      "\n",
      "Base-DT sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4335  2359  4440  2161]\n",
      " [ 2590 12985  7488  3913]\n",
      " [ 4512  8003 18264  8034]\n",
      " [ 2625  4521  9870 24174]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.31      0.33      0.32     13295\n",
      "    negative       0.47      0.48      0.47     26976\n",
      "     neutral       0.46      0.47      0.46     38813\n",
      "    positive       0.63      0.59      0.61     41190\n",
      "\n",
      "    accuracy                           0.50    120274\n",
      "   macro avg       0.47      0.47      0.47    120274\n",
      "weighted avg       0.50      0.50      0.50    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Decision Tree Classifier for both emotions and sentiments.\n",
    "\n",
    "# Emotions:\n",
    "dtc_emotions = tree.DecisionTreeClassifier()\n",
    "#train DTC emotions model\n",
    "dtc_model_emotions = dtc_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test DTC emotions model\n",
    "dtc_predict_emotions = dtc_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "# Sentiments:\n",
    "dtc_sentiments = tree.DecisionTreeClassifier()\n",
    "#train DTC sentiments model\n",
    "dtc_model_sentiments = dtc_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test DTC sentiments model\n",
    "dtc_predict_sentiments = dtc_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(dtc_predict_emotions, y_test_emotions, \"Base-DT emotions\", \"default parameters\")\n",
    "classification_performance(dtc_predict_sentiments, y_test_sentiments, \"Base-DT sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41357517",
   "metadata": {},
   "source": [
    "### 2.5.3 Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "329dc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MLP emotions with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2829    66     0     1     6     0     0     2     0     0     2     0\n",
      "      0     0     0    99     0    36   242     0  3979    27     0     0\n",
      "      0     2     0     2]\n",
      " [  126  2023     1     0     2     0     0     1     0     0     3     0\n",
      "      0     0     0    26     0    10    30     0  1988     5     0     0\n",
      "      0     0     0     0]\n",
      " [   33    39    43    10     6     1     1     0     0     0     6     0\n",
      "      0     0     0    20     0     5    20     0  3501     8     0     0\n",
      "      0     0     1     0]\n",
      " [   75   121    13     9    16     2     0     0     0     0    10     0\n",
      "      0     0     0    59     0     5    47     0  5561    14     0     0\n",
      "      0     2     1     0]\n",
      " [  319    83     0     2   112     1     0     6     0     0     5     0\n",
      "      0     0     0    40     0    17    97     0  7086    32     0     0\n",
      "      0     3     1     0]\n",
      " [  122    21     0     0     4     5     0     0     0     0     4     0\n",
      "      0     0     0    51     0    17    40     0  2167    61     0     0\n",
      "      0    13     1     0]\n",
      " [   32    59     2     0     7     0    10     3     0     0     4     0\n",
      "      0     0     0     9     0     5    21     0  3275     4     0     0\n",
      "      0     1     1     0]\n",
      " [   51    37     0     0     5     0     3   114     0     0     1     0\n",
      "      0     0     0    18     0     3    35     0  3871     1     0     0\n",
      "      0     1     0     0]\n",
      " [   47    21     0     0     4     0     0     1     0     0     0     0\n",
      "      0     0     0    11     0     3    41     0  1355    44     0     0\n",
      "      0     0     0     0]\n",
      " [   44    33     1     1     5     0     1     0     0     0     4     0\n",
      "      0     0     0    17     0     3    20     0  3092    16     0     0\n",
      "      0     9     6     0]\n",
      " [   47    79     2     4     9     0     0     2     0     0    28     0\n",
      "      0     0     0    25     0     2    46     0  5044    16     0     0\n",
      "      0     7     2     0]\n",
      " [   17    27     7     7     7     0     0     0     0     0     2     0\n",
      "      0     0     0     4     0     0     9     0  1947     7     0     0\n",
      "      0     1     0     0]\n",
      " [   18    16     2     3     4     0     0     0     0     0     0     0\n",
      "      0     0     0     4     0     1     6     0   934     2     0     0\n",
      "      0     5     0     0]\n",
      " [  180    34     1     0     4     0     0     1     0     0     0     0\n",
      "      0     0     0    30     0    70    44     0  1739     9     0     0\n",
      "      0     0     0     2]\n",
      " [   14    20     0     0     1     1     1     0     0     0     3     0\n",
      "      0     0     0     2     0     0     6     0  1161     5     0     0\n",
      "      0     0     0     0]\n",
      " [  282    28     0     1     5     0     0     0     0     0     0     0\n",
      "      0     0     0  3737     0    50    24     0   784    19     0     0\n",
      "      0    10     3     0]\n",
      " [    8     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     1     0   213     1     0     0\n",
      "      0     8     0     0]\n",
      " [  247   262     3     2     8     1     0     0     0     0     0     0\n",
      "      0     0     0   115     0   274   162     0  2008    14     0     0\n",
      "      0     1     0     0]\n",
      " [  121    43     0     1     5     0     1     0     0     0     0     0\n",
      "      0     0     0    19     0    10  2047     0  1232     6     0     0\n",
      "      0     1     0     0]\n",
      " [    0     2     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     3     0   531     1     0     0\n",
      "      0     0     1     0]\n",
      " [  628   523    14     8    54     3     0    16     0     0    37     1\n",
      "      0     0     0   212     0    57   408     0 36857   120     0     0\n",
      "      0    10     6     0]\n",
      " [  194    31     0     0     7     0     0     0     0     0     2     0\n",
      "      0     0     0    61     0    12    40     0  2355   444     0     0\n",
      "      0     1     0     0]\n",
      " [   51     4     0     0     1     0     0     0     0     0     1     0\n",
      "      0     0     0     5     0     4     3     0   393     1     0     0\n",
      "      0     0     0     0]\n",
      " [   62    50     0     2     9     0     1     0     0     0     5     0\n",
      "      0     0     0     9     0     4    26     0  3073     7     0     0\n",
      "      0     6     1     0]\n",
      " [   32     6     0     0     2     0     0     0     0     0     0     0\n",
      "      0     0     0    51     0    15     2     0   431     2     0     0\n",
      "      0     0     0     0]\n",
      " [   10    17     0     2     0     0     1     0     0     0     0     0\n",
      "      0     0     0    20     0     0     8     0   865     9     0     0\n",
      "      0   103    13     0]\n",
      " [   28    31     1     5     6     0     0     0     0     0     1     0\n",
      "      0     0     0    16     0     5    18     0  2456    10     0     0\n",
      "      0    71    41     0]\n",
      " [  114    27     1     0     0     0     0     1     0     0     0     0\n",
      "      0     1     0     7     0     9    14     0  2225     4     0     0\n",
      "      0     0     0     3]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.49      0.39      0.43      7293\n",
      "     amusement       0.55      0.48      0.51      4215\n",
      "         anger       0.47      0.01      0.02      3694\n",
      "     annoyance       0.16      0.00      0.00      5935\n",
      "      approval       0.39      0.01      0.03      7804\n",
      "        caring       0.36      0.00      0.00      2506\n",
      "     confusion       0.53      0.00      0.01      3433\n",
      "     curiosity       0.78      0.03      0.05      4140\n",
      "        desire       0.00      0.00      0.00      1527\n",
      "disappointment       0.00      0.00      0.00      3252\n",
      "   disapproval       0.24      0.01      0.01      5313\n",
      "       disgust       0.00      0.00      0.00      2035\n",
      " embarrassment       0.00      0.00      0.00       995\n",
      "    excitement       0.00      0.00      0.00      2114\n",
      "          fear       0.00      0.00      0.00      1214\n",
      "     gratitude       0.80      0.76      0.78      4943\n",
      "         grief       0.00      0.00      0.00       234\n",
      "           joy       0.44      0.09      0.15      3097\n",
      "          love       0.59      0.59      0.59      3486\n",
      "   nervousness       0.00      0.00      0.00       541\n",
      "       neutral       0.37      0.95      0.53     38954\n",
      "      optimism       0.50      0.14      0.22      3147\n",
      "         pride       0.00      0.00      0.00       463\n",
      "   realization       0.00      0.00      0.00      3255\n",
      "        relief       0.00      0.00      0.00       541\n",
      "       remorse       0.40      0.10      0.16      1048\n",
      "       sadness       0.53      0.02      0.03      2689\n",
      "      surprise       0.43      0.00      0.00      2406\n",
      "\n",
      "      accuracy                           0.40    120274\n",
      "     macro avg       0.29      0.13      0.13    120274\n",
      "  weighted avg       0.37      0.40      0.28    120274\n",
      "\n",
      "\n",
      "Base-MLP sentiments with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2274  2227  6024  2770]\n",
      " [  687 13576  8545  4168]\n",
      " [ 1360  6963 21270  9220]\n",
      " [  577  3430  8691 28492]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.46      0.17      0.25     13295\n",
      "    negative       0.52      0.50      0.51     26976\n",
      "     neutral       0.48      0.55      0.51     38813\n",
      "    positive       0.64      0.69      0.66     41190\n",
      "\n",
      "    accuracy                           0.55    120274\n",
      "   macro avg       0.52      0.48      0.48    120274\n",
      "weighted avg       0.54      0.55      0.53    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Perceptron Classifier for both emotions and sentiments.\n",
    "\n",
    "mlp_emotions = MLPClassifier(max_iter=1)\n",
    "#train MLP emotions model\n",
    "mlp_model_emotions = mlp_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test MLP emotions model\n",
    "mlp_predict_emotions = mlp_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "mlp_sentiments = MLPClassifier(max_iter=1)\n",
    "#train MLP sentiments model\n",
    "mlp_model_sentiments = mlp_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test MLP sentiments model\n",
    "mlp_predict_sentiments = mlp_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mlp_predict_emotions, y_test_emotions, \"Base-MLP emotions\", \"default parameters\")\n",
    "classification_performance(mlp_predict_sentiments, y_test_sentiments, \"Base-MLP sentiments\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439ec9e",
   "metadata": {},
   "source": [
    "### 2.5.4 Top-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c5ce7844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-MNB emotions with alpha : [0, 0.5, 1.5, 2.0]:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2803    40    11    35   184    11     5    20     1     5    20     1\n",
      "      1    13     0   171     0    50   116     0  3737    26     0    13\n",
      "      0     0     5    25]\n",
      " [  134  1023    13    47    70     1     6     8     0     1    23     3\n",
      "      1    10     1    31     0    28    16     0  2777     4     0     9\n",
      "      0     0     1     8]\n",
      " [   38    29   293   224    66     7    13    11     1    24    63    20\n",
      "      0     1     4    15     0     7     2     0  2844    10     0     4\n",
      "      0     2     6    10]\n",
      " [   90    58    98   322   154    11    28    20     0    36   131    28\n",
      "      1     2     5    44     0     9    14     0  4825    12     0    20\n",
      "      0     2    17     8]\n",
      " [  325    57    13    96   668    20    35    19     2    16   101     6\n",
      "      0    14     1    53     0    16    45     0  6211    43     0    33\n",
      "      0     1    17    12]\n",
      " [   54     5     4    18    64    82     3     4     1     9    20     2\n",
      "      0     0     0    78     0    15     7     0  2081    46     0     4\n",
      "      0     2     6     1]\n",
      " [   32    29     9    28    63     2   125    87     1    10    60     2\n",
      "      2     0     3    12     0     1     6     0  2930     5     0    22\n",
      "      0     0     2     2]\n",
      " [   70    23    17    38    78     7    53   294     2     5    29     5\n",
      "      0     5     0    20     0     4     7     0  3445    12     0    10\n",
      "      0     2     2    12]\n",
      " [   42    10     3    11    52     2     4     4    29     4    13     0\n",
      "      0     3     2    11     0     5    13     0  1280    37     0     1\n",
      "      0     0     0     1]\n",
      " [   52    17     9    81    85     4    10     9     1    91    59     7\n",
      "      0     0     2    17     0     7     5     0  2715    13     0    19\n",
      "      0     2    41     6]\n",
      " [   66    36    23   139   188     7    34    17     1    29   354    15\n",
      "      3     3     2    20     0     7     9     0  4318     9     0    20\n",
      "      0     0    12     1]\n",
      " [   42     7    55    99    60     1     4     2     1    19    42   102\n",
      "      2     0     2     7     1     2     4     0  1561     5     0     5\n",
      "      0     2     6     4]\n",
      " [   15     7    10    33    26     1     2     3     0    11    17     5\n",
      "      9     0     0     5     0     0     3     0   830     2     0     7\n",
      "      0     1     5     3]\n",
      " [  185    27    17    17    49     3     6    21     2     8     8     4\n",
      "      0    49     0    34     0    98    18     0  1515    14     0    10\n",
      "      0     0     1    28]\n",
      " [   23     9     3    19    21     4     3     3     0    13    24     7\n",
      "      0     1    38     3     0     1     0     0  1013     7     0     5\n",
      "      0     0    10     7]\n",
      " [  254    19     0    10    42    13     2     2     0     2    19     0\n",
      "      0     4     0  3000     0    39     8     0  1492    26     0     4\n",
      "      0     5     2     0]\n",
      " [    2     0     3     2     6     0     1     1     0     2     1     1\n",
      "      0     0     0     8     0     0     0     0   199     1     0     0\n",
      "      0     0     7     0]\n",
      " [  259   171     7    14    73     2     3     0     2     2     8     0\n",
      "      1    19     1    98     0   247    75     0  2091    10     0     7\n",
      "      0     0     3     4]\n",
      " [  263    23     4     6    64     0     2     4     1     5    13     0\n",
      "      0     2     0    19     0    26   958     0  2080    12     0     1\n",
      "      0     1     1     1]\n",
      " [    3     1     4     8    22     4     3     0     0     5    10     0\n",
      "      1     0     0     4     0     0     0     0   466     1     0     4\n",
      "      0     0     4     1]\n",
      " [ 1047   373   226   611  1203   130   191   280    13   185   700    70\n",
      "     11    74    25   294     1   158   195     1 32600   161     6   193\n",
      "      0     6   102    98]\n",
      " [  152     6     3    19    96    25     9     7     7     6    21     2\n",
      "      0     2     0    65     0    10     9     0  2431   270     0     5\n",
      "      0     0     2     0]\n",
      " [   65     3     3     8    11     1     1     1     0     3     5     0\n",
      "      0     1     0    11     0     2     3     0   339     3     0     1\n",
      "      0     0     1     1]\n",
      " [   52    20    11    41   110     1    17    14     0    13    64     1\n",
      "      1     0     1    10     0    11     8     0  2768     4     0    96\n",
      "      0     0     4     8]\n",
      " [   35     3     3     4    26     1     2     2     0     1     3     0\n",
      "      0     1     0    25     0    11     1     0   417     2     0     2\n",
      "      0     0     1     1]\n",
      " [    4     3     1    19    19     3     2     2     2     8     9     1\n",
      "      0     0     0    60     0     0     5     0   814     3     0     8\n",
      "      0    46    37     2]\n",
      " [   24    20    15    38    37     6     2     6     0    41    38     9\n",
      "      0     2     2    29     0     4     3     0  2215     8     0     7\n",
      "      0    20   159     4]\n",
      " [  129    21    23    36    53     3    16    30     0     4    26     5\n",
      "      0     5     1     9     0     9     7     0  1856     6     0    15\n",
      "      0     0     3   149]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.45      0.38      0.41      7293\n",
      "     amusement       0.50      0.24      0.33      4215\n",
      "         anger       0.33      0.08      0.13      3694\n",
      "     annoyance       0.16      0.05      0.08      5935\n",
      "      approval       0.19      0.09      0.12      7804\n",
      "        caring       0.23      0.03      0.06      2506\n",
      "     confusion       0.21      0.04      0.06      3433\n",
      "     curiosity       0.34      0.07      0.12      4140\n",
      "        desire       0.43      0.02      0.04      1527\n",
      "disappointment       0.16      0.03      0.05      3252\n",
      "   disapproval       0.19      0.07      0.10      5313\n",
      "       disgust       0.34      0.05      0.09      2035\n",
      " embarrassment       0.27      0.01      0.02       995\n",
      "    excitement       0.23      0.02      0.04      2114\n",
      "          fear       0.42      0.03      0.06      1214\n",
      "     gratitude       0.72      0.61      0.66      4943\n",
      "         grief       0.00      0.00      0.00       234\n",
      "           joy       0.32      0.08      0.13      3097\n",
      "          love       0.62      0.27      0.38      3486\n",
      "   nervousness       0.00      0.00      0.00       541\n",
      "       neutral       0.35      0.84      0.50     38954\n",
      "      optimism       0.36      0.09      0.14      3147\n",
      "         pride       0.00      0.00      0.00       463\n",
      "   realization       0.18      0.03      0.05      3255\n",
      "        relief       0.00      0.00      0.00       541\n",
      "       remorse       0.50      0.04      0.08      1048\n",
      "       sadness       0.35      0.06      0.10      2689\n",
      "      surprise       0.38      0.06      0.11      2406\n",
      "\n",
      "      accuracy                           0.36    120274\n",
      "     macro avg       0.29      0.12      0.14    120274\n",
      "  weighted avg       0.34      0.36      0.28    120274\n",
      "\n",
      "\n",
      "Top-MNB sentiments with alpha : [0, 0.5, 1.5, 2.0]:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2693  2284  4942  3376]\n",
      " [ 1175 12982  7696  5123]\n",
      " [ 2380  7177 17766 11490]\n",
      " [ 1142  3509  8013 28526]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.36      0.20      0.26     13295\n",
      "    negative       0.50      0.48      0.49     26976\n",
      "     neutral       0.46      0.46      0.46     38813\n",
      "    positive       0.59      0.69      0.64     41190\n",
      "\n",
      "    accuracy                           0.52    120274\n",
      "   macro avg       0.48      0.46      0.46    120274\n",
      "weighted avg       0.50      0.52      0.51    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "search_space_MNB = {\n",
    "    \"alpha\" : [0, 0.5, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "gs_mnb_emotions = GridSearchCV(estimator=MultinomialNB(), param_grid = search_space_MNB)\n",
    "#train GS MNB emotions model\n",
    "gs_mnb_model_emotions = gs_mnb_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test GS MNB emotions model\n",
    "gs_mnb_predict_emotions = gs_mnb_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "\n",
    "gs_mnb_sentiments = GridSearchCV(estimator=MultinomialNB(), param_grid = search_space_MNB)\n",
    "#train GS MNB sentiments model\n",
    "gs_mnb_model_sentiments = gs_mnb_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test GS MNB sentiments model\n",
    "gs_mnb_predict_sentiments = gs_mnb_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(gs_mnb_predict_emotions, y_test_emotions, \"Top-MNB emotions\", \"alpha : [0, 0.5, 1.5, 2.0]\")\n",
    "classification_performance(gs_mnb_predict_sentiments, y_test_sentiments, \"Top-MNB sentiments\", \"alpha : [0, 0.5, 1.5, 2.0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e543695",
   "metadata": {},
   "source": [
    "### 2.5.5 Top-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "82c1f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-DT emotions with criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1545    37     2     0     1     0     0     1     3     0     0     0\n",
      "      1     7     2    52     0   119   281     0  5170    64     0     0\n",
      "      1     7     0     0]\n",
      " [   92  1400     4     0     0     3     0     3     0     0     1     5\n",
      "      1     4     0    25     0    19    30     0  2603    17     0     1\n",
      "      1     6     0     0]\n",
      " [   58    25     2     0     0     1     1     0     0     0     0     0\n",
      "      0     2     0    16     0    15    19     0  3536     8     0     0\n",
      "      0    11     0     0]\n",
      " [   97    80     2     8     1     2     1     1     0     0     3     0\n",
      "      0     0     0    41     0    24    52     0  5575    24     0     0\n",
      "      0    23     0     1]\n",
      " [  344    63     0     0     0     5     1     0     0     1     0     1\n",
      "      0     0     0    27     0    62   107     0  7108    60     0     0\n",
      "      0    22     3     0]\n",
      " [  100    14     0     1     0     8     0     0     0     0     0     0\n",
      "      0     0     0    11     0    61    47     0  2094   123     0     0\n",
      "      0    43     4     0]\n",
      " [   46    38     0     0     0     0     5     2     0     0     0     0\n",
      "      1     0     0     6     0    19    23     0  3275     4     0     0\n",
      "      0    14     0     0]\n",
      " [   69    32     0     0     0     0     1     2     0     0     0     0\n",
      "      1     1     0    17     0    15    40     0  3942     5     0     0\n",
      "      0    15     0     0]\n",
      " [   57    14     0     1     0     1     0     0     2     0     0     0\n",
      "      0     0     0     4     0    13    39     0  1316    78     0     0\n",
      "      1     0     1     0]\n",
      " [   77    26     0     1     0     1     0     0     1     0     1     0\n",
      "      1     0     1    12     0    24    20     0  3019    24     0     0\n",
      "      0    39     5     0]\n",
      " [  103    58     0     4     1     3     0     0     1     0     0     0\n",
      "      0     0     0    25     0    25    41     0  4992    26     0     0\n",
      "      0    32     2     0]\n",
      " [   25    15     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     1     4     0     3     9     0  1962     8     0     0\n",
      "      0     8     0     0]\n",
      " [   17    11     0     2     0     0     1     0     0     0     0     0\n",
      "      1     0     0     0     0     3     6     0   926     5     0     0\n",
      "      0    23     0     0]\n",
      " [   74    21     0     0     0     0     0     0     2     0     0     0\n",
      "      0    44     0     8     0   105    46     0  1793    17     0     0\n",
      "      0     4     0     0]\n",
      " [   11    18     0     0     0     0     0     1     0     0     0     0\n",
      "      0     0     1     0     0     1     6     0  1164     9     0     0\n",
      "      0     2     1     0]\n",
      " [  194    17     0    25     1     5     0     0     0     0     0     0\n",
      "      4    12     0  3554     0   163    28     0   745    86     0     0\n",
      "     11    83     3    12]\n",
      " [    8     0     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     3     2     0   206     1     0     0\n",
      "      0    10     1     0]\n",
      " [  166   104     0     1     0     1     0     0     1     0     0     0\n",
      "      0    53     3    23     0   633   159     0  1914    34     0     0\n",
      "      0     5     0     0]\n",
      " [   43    35     2     3     0     9     6     0     4     2     4     0\n",
      "      0     7     3    19     0    19  2088     0  1230     9     0     0\n",
      "      0     3     0     0]\n",
      " [    3     0     0     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     1     2     0   526     4     0     0\n",
      "      0     3     0     0]\n",
      " [  751   404     1    16     1    12     4     4     4     0     2     0\n",
      "      2    19     1   157     0   224   431     0 36587   210     0     0\n",
      "      1   116     7     0]\n",
      " [  166    17     1     0     0    10     0     0     0     0     0     0\n",
      "      0     1     0    17     0    43    40     0  2057   787     0     0\n",
      "      0     7     1     0]\n",
      " [   26     4     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0    24     3     0   402     3     0     0\n",
      "      0     1     0     0]\n",
      " [   65    34     1     0     0     1     0     0     0     0     0     1\n",
      "      1     0     1     8     0    12    33     0  3063    12     0     1\n",
      "      0    19     3     0]\n",
      " [   40     5     0     2     0     0     0     0     0     0     0     0\n",
      "      1     0     0    24     0    62     2     0   391     6     0     0\n",
      "      8     0     0     0]\n",
      " [    8    14     0     0     0     3     0     0     0     0     2     0\n",
      "      2     0     0     3     0     3     8     0   479     5     0     0\n",
      "      0   489    32     0]\n",
      " [   42    24     0     0     1     2     0     0     0     0     0     0\n",
      "      0     0     0     2     0    15    15     0  2315    22     0     0\n",
      "      1   236    14     0]\n",
      " [   32    15     0     1     1     0     0     0     0     0     0     0\n",
      "      0     9     0     4     0    11    12     0  2311     7     0     0\n",
      "      0     3     0     0]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.36      0.21      0.27      7293\n",
      "     amusement       0.55      0.33      0.42      4215\n",
      "         anger       0.13      0.00      0.00      3694\n",
      "     annoyance       0.12      0.00      0.00      5935\n",
      "      approval       0.00      0.00      0.00      7804\n",
      "        caring       0.12      0.00      0.01      2506\n",
      "     confusion       0.25      0.00      0.00      3433\n",
      "     curiosity       0.14      0.00      0.00      4140\n",
      "        desire       0.11      0.00      0.00      1527\n",
      "disappointment       0.00      0.00      0.00      3252\n",
      "   disapproval       0.00      0.00      0.00      5313\n",
      "       disgust       0.00      0.00      0.00      2035\n",
      " embarrassment       0.06      0.00      0.00       995\n",
      "    excitement       0.28      0.02      0.04      2114\n",
      "          fear       0.08      0.00      0.00      1214\n",
      "     gratitude       0.87      0.72      0.79      4943\n",
      "         grief       0.00      0.00      0.00       234\n",
      "           joy       0.37      0.20      0.26      3097\n",
      "          love       0.58      0.60      0.59      3486\n",
      "   nervousness       0.00      0.00      0.00       541\n",
      "       neutral       0.36      0.94      0.52     38954\n",
      "      optimism       0.47      0.25      0.33      3147\n",
      "         pride       0.00      0.00      0.00       463\n",
      "   realization       0.50      0.00      0.00      3255\n",
      "        relief       0.33      0.01      0.03       541\n",
      "       remorse       0.40      0.47      0.43      1048\n",
      "       sadness       0.18      0.01      0.01      2689\n",
      "      surprise       0.00      0.00      0.00      2406\n",
      "\n",
      "      accuracy                           0.39    120274\n",
      "     macro avg       0.22      0.13      0.13    120274\n",
      "  weighted avg       0.29      0.39      0.27    120274\n",
      "\n",
      "\n",
      "Top-DT sentiments with criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   96    92 12557   550]\n",
      " [   41  1152 24559  1224]\n",
      " [   53   242 36400  2118]\n",
      " [  108   433 26782 13867]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.32      0.01      0.01     13295\n",
      "    negative       0.60      0.04      0.08     26976\n",
      "     neutral       0.36      0.94      0.52     38813\n",
      "    positive       0.78      0.34      0.47     41190\n",
      "\n",
      "    accuracy                           0.43    120274\n",
      "   macro avg       0.52      0.33      0.27    120274\n",
      "weighted avg       0.55      0.43      0.35    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "search_space_DT = {\n",
    "    \"criterion\" : np.array([\"entropy\"]),\n",
    "    \"max_depth\" : np.array([10, 11]),\n",
    "    \"min_samples_split\" : np.array([5, 10, 15])\n",
    "}\n",
    "\n",
    "gs_dt_emotions = GridSearchCV(tree.DecisionTreeClassifier(), search_space_DT)\n",
    "#train GS DT emotions model\n",
    "gs_dt_model_emotions = gs_dt_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "#test GS DT emotions model\n",
    "gs_dt_predict_emotions = gs_dt_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "gs_dt_sentiments = GridSearchCV(tree.DecisionTreeClassifier(), search_space_DT)\n",
    "#train GS DT model sentiments\n",
    "gs_dt_model_sentiments = gs_dt_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "#test GS DT model sentiments\n",
    "gs_dt_predict_sentiments = gs_dt_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(gs_dt_predict_emotions, y_test_emotions, \"Top-DT emotions\", \"criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15\")\n",
    "classification_performance(gs_dt_predict_sentiments, y_test_sentiments, \"Top-DT sentiments\", \"criterion: entropy, max_depth: 10, 11, min_sample: 5, 10, 15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947ce3f",
   "metadata": {},
   "source": [
    "### 2.5.6 Top-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bcc15bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-MLP emotions with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1545    37     2     0     1     0     0     1     3     0     0     0\n",
      "      1     7     2    52     0   119   281     0  5170    64     0     0\n",
      "      1     7     0     0]\n",
      " [   92  1400     4     0     0     3     0     3     0     0     1     5\n",
      "      1     4     0    25     0    19    30     0  2603    17     0     1\n",
      "      1     6     0     0]\n",
      " [   58    25     2     0     0     1     1     0     0     0     0     0\n",
      "      0     2     0    16     0    15    19     0  3536     8     0     0\n",
      "      0    11     0     0]\n",
      " [   97    80     2     8     1     2     1     1     0     0     3     0\n",
      "      0     0     0    41     0    24    52     0  5575    24     0     0\n",
      "      0    23     0     1]\n",
      " [  344    63     0     0     0     5     1     0     0     1     0     1\n",
      "      0     0     0    27     0    62   107     0  7108    60     0     0\n",
      "      0    22     3     0]\n",
      " [  100    14     0     1     0     8     0     0     0     0     0     0\n",
      "      0     0     0    11     0    61    47     0  2094   123     0     0\n",
      "      0    43     4     0]\n",
      " [   46    38     0     0     0     0     5     2     0     0     0     0\n",
      "      1     0     0     6     0    19    23     0  3275     4     0     0\n",
      "      0    14     0     0]\n",
      " [   69    32     0     0     0     0     1     2     0     0     0     0\n",
      "      1     1     0    17     0    15    40     0  3942     5     0     0\n",
      "      0    15     0     0]\n",
      " [   57    14     0     1     0     1     0     0     2     0     0     0\n",
      "      0     0     0     4     0    13    39     0  1316    78     0     0\n",
      "      1     0     1     0]\n",
      " [   77    26     0     1     0     1     0     0     1     0     1     0\n",
      "      1     0     1    12     0    24    20     0  3019    24     0     0\n",
      "      0    39     5     0]\n",
      " [  103    58     0     4     1     3     0     0     1     0     0     0\n",
      "      0     0     0    25     0    25    41     0  4992    26     0     0\n",
      "      0    32     2     0]\n",
      " [   25    15     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     1     4     0     3     9     0  1962     8     0     0\n",
      "      0     8     0     0]\n",
      " [   17    11     0     2     0     0     1     0     0     0     0     0\n",
      "      1     0     0     0     0     3     6     0   926     5     0     0\n",
      "      0    23     0     0]\n",
      " [   74    21     0     0     0     0     0     0     2     0     0     0\n",
      "      0    44     0     8     0   105    46     0  1793    17     0     0\n",
      "      0     4     0     0]\n",
      " [   11    18     0     0     0     0     0     1     0     0     0     0\n",
      "      0     0     1     0     0     1     6     0  1164     9     0     0\n",
      "      0     2     1     0]\n",
      " [  194    17     0    25     1     5     0     0     0     0     0     0\n",
      "      4    12     0  3554     0   163    28     0   745    86     0     0\n",
      "     11    83     3    12]\n",
      " [    8     0     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     3     2     0   206     1     0     0\n",
      "      0    10     1     0]\n",
      " [  166   104     0     1     0     1     0     0     1     0     0     0\n",
      "      0    53     3    23     0   633   159     0  1914    34     0     0\n",
      "      0     5     0     0]\n",
      " [   43    35     2     3     0     9     6     0     4     2     4     0\n",
      "      0     7     3    19     0    19  2088     0  1230     9     0     0\n",
      "      0     3     0     0]\n",
      " [    3     0     0     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     1     2     0   526     4     0     0\n",
      "      0     3     0     0]\n",
      " [  751   404     1    16     1    12     4     4     4     0     2     0\n",
      "      2    19     1   157     0   224   431     0 36587   210     0     0\n",
      "      1   116     7     0]\n",
      " [  166    17     1     0     0    10     0     0     0     0     0     0\n",
      "      0     1     0    17     0    43    40     0  2057   787     0     0\n",
      "      0     7     1     0]\n",
      " [   26     4     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0    24     3     0   402     3     0     0\n",
      "      0     1     0     0]\n",
      " [   65    34     1     0     0     1     0     0     0     0     0     1\n",
      "      1     0     1     8     0    12    33     0  3063    12     0     1\n",
      "      0    19     3     0]\n",
      " [   40     5     0     2     0     0     0     0     0     0     0     0\n",
      "      1     0     0    24     0    62     2     0   391     6     0     0\n",
      "      8     0     0     0]\n",
      " [    8    14     0     0     0     3     0     0     0     0     2     0\n",
      "      2     0     0     3     0     3     8     0   479     5     0     0\n",
      "      0   489    32     0]\n",
      " [   42    24     0     0     1     2     0     0     0     0     0     0\n",
      "      0     0     0     2     0    15    15     0  2315    22     0     0\n",
      "      1   236    14     0]\n",
      " [   32    15     0     1     1     0     0     0     0     0     0     0\n",
      "      0     9     0     4     0    11    12     0  2311     7     0     0\n",
      "      0     3     0     0]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.36      0.21      0.27      7293\n",
      "     amusement       0.55      0.33      0.42      4215\n",
      "         anger       0.13      0.00      0.00      3694\n",
      "     annoyance       0.12      0.00      0.00      5935\n",
      "      approval       0.00      0.00      0.00      7804\n",
      "        caring       0.12      0.00      0.01      2506\n",
      "     confusion       0.25      0.00      0.00      3433\n",
      "     curiosity       0.14      0.00      0.00      4140\n",
      "        desire       0.11      0.00      0.00      1527\n",
      "disappointment       0.00      0.00      0.00      3252\n",
      "   disapproval       0.00      0.00      0.00      5313\n",
      "       disgust       0.00      0.00      0.00      2035\n",
      " embarrassment       0.06      0.00      0.00       995\n",
      "    excitement       0.28      0.02      0.04      2114\n",
      "          fear       0.08      0.00      0.00      1214\n",
      "     gratitude       0.87      0.72      0.79      4943\n",
      "         grief       0.00      0.00      0.00       234\n",
      "           joy       0.37      0.20      0.26      3097\n",
      "          love       0.58      0.60      0.59      3486\n",
      "   nervousness       0.00      0.00      0.00       541\n",
      "       neutral       0.36      0.94      0.52     38954\n",
      "      optimism       0.47      0.25      0.33      3147\n",
      "         pride       0.00      0.00      0.00       463\n",
      "   realization       0.50      0.00      0.00      3255\n",
      "        relief       0.33      0.01      0.03       541\n",
      "       remorse       0.40      0.47      0.43      1048\n",
      "       sadness       0.18      0.01      0.01      2689\n",
      "      surprise       0.00      0.00      0.00      2406\n",
      "\n",
      "      accuracy                           0.39    120274\n",
      "     macro avg       0.22      0.13      0.13    120274\n",
      "  weighted avg       0.29      0.39      0.27    120274\n",
      "\n",
      "\n",
      "Top-MLP sentiments with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   96    92 12557   550]\n",
      " [   41  1152 24559  1224]\n",
      " [   53   242 36400  2118]\n",
      " [  108   433 26782 13867]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.32      0.01      0.01     13295\n",
      "    negative       0.60      0.04      0.08     26976\n",
      "     neutral       0.36      0.94      0.52     38813\n",
      "    positive       0.78      0.34      0.47     41190\n",
      "\n",
      "    accuracy                           0.43    120274\n",
      "   macro avg       0.52      0.33      0.27    120274\n",
      "weighted avg       0.55      0.43      0.35    120274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Top-MLP\n",
    "search_space_Top_MLP = {\n",
    "    'activation' : np.array(['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'hidden_layer_sizes' : [(30, 50), (10, 10, 10)],\n",
    "    'solver' : ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "gs_mlp_model_emotions = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP)\n",
    "\n",
    "# Emotions:\n",
    "#train GS MLP emotions model\n",
    "gs_mlp_model_emotions.fit(X_train_emotions, y_train_emotions)\n",
    "\n",
    "#test GS MLP emotions model\n",
    "gs_mlp_predict_emotions = gs_dt_model_emotions.predict(X_test_emotions)\n",
    "\n",
    "# Sentiments:\n",
    "gs_mlp_model_sentiments = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP)\n",
    "\n",
    "#train GS MLP emotions model\n",
    "gs_mlp_model_sentiments.fit(X_train_sentiments, y_train_sentiments)\n",
    "\n",
    "#test GS MLP emotions model\n",
    "gs_mlp_predict_sentiments = gs_dt_model_sentiments.predict(X_test_sentiments)\n",
    "\n",
    "classification_performance(gs_mlp_predict_emotions, y_test_emotions, \"Top-MLP emotions\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")\n",
    "classification_performance(gs_mlp_predict_sentiments, y_test_sentiments, \"Top-MLP sentiments\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d4118",
   "metadata": {},
   "source": [
    "## 3. Embeddings as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965c3bf",
   "metadata": {},
   "source": [
    "### 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "86591a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc80898",
   "metadata": {},
   "source": [
    "### 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d817f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2  Use the tokenizer from nltk to extract words from the Reddit posts. Display the number\n",
    "# of tokens in the training set.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def comment_tokenizer(comments):\n",
    "    tokenized_comments = []\n",
    "\n",
    "    for comment in comments:\n",
    "        token_comment = word_tokenize(comment)\n",
    "        tokenized_comments.append(token_comment)\n",
    "    return tokenized_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f7cd3",
   "metadata": {},
   "source": [
    "### 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2dfc112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Compute the embedding of a Reddit post as the average of the embeddings of its words. If\n",
    "# a word has no embedding in Word2Vec, skip it.\n",
    "\n",
    "def embedded_comments(tokenized_comments):\n",
    "    comment_embeddings = []\n",
    "    hit_count = 0\n",
    "    token_count = 0\n",
    "    \n",
    "    for comment in tokenized_comments:\n",
    "        comment_token_embeddings = []\n",
    "        for token in comment:\n",
    "            token_count += 1\n",
    "            try:\n",
    "                embedded_token = wv[token]\n",
    "                comment_token_embeddings.append(embedded_token)\n",
    "                hit_count += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if len(comment_token_embeddings) != 0: \n",
    "            tkn_embdng = np.array(comment_token_embeddings)\n",
    "            comment_embeddings.append(np.mean(tkn_embdng, axis=0))\n",
    "        else:\n",
    "            comment_embeddings.append(np.zeros(300))\n",
    "    return comment_embeddings, hit_count, token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c7273c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split dataset for emotions classification\n",
    "X_train_emotions, X_test_emotions, y_train_emotions, y_test_emotions = train_test_split(comments,y_emotions, test_size=0.2)\n",
    "\n",
    "#split dataset for sentiments classification\n",
    "X_train_sentiments, X_test_sentiments, y_train_sentiments, y_test_sentiments = train_test_split(comments,y_sentiments, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2ea8fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_X_train_emotions = comment_tokenizer(X_train_emotions)\n",
    "tokenized_X_test_emotions = comment_tokenizer(X_test_emotions)\n",
    "tokenized_X_train_sentiments = comment_tokenizer(X_train_sentiments)\n",
    "tokenized_X_test_sentiments = comment_tokenizer(X_test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8ab50884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emotions_embeddings, X_train_emotions_hit_count, X_train_emotions_token_count = embedded_comments(tokenized_X_train_emotions)\n",
    "X_test_emotions_embeddings, X_test_emotions_hit_count, X_test_emotions_token_count = embedded_comments(tokenized_X_test_emotions)\n",
    "X_train_sentiments_embeddings, X_train_sentiments_hit_count, X_train_sentiments_token_count = embedded_comments(tokenized_X_train_sentiments)\n",
    "X_test_sentiments_embeddings, X_test_sentiments_hit_count, X_test_sentiments_token_count = embedded_comments(tokenized_X_test_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "61dc067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the training set: 2112688\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in the training set: \"+ str(X_train_emotions_token_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59948508",
   "metadata": {},
   "source": [
    "### 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "81b25108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions training dataset hit rate 0.7745251546844588\n",
      "Emotions test dataset hit rate 0.7744314747657902\n",
      "Sentiments test dataset hit rate 0.7745826903529737\n",
      "Sentiments test dataset hit rate 0.7742029061947836\n"
     ]
    }
   ],
   "source": [
    "X_train_emotions_hit_rate = X_train_emotions_hit_count / X_train_emotions_token_count\n",
    "print(\"Emotions training dataset hit rate\", X_train_emotions_hit_rate)\n",
    "\n",
    "X_test_emotions_hit_rate = X_test_emotions_hit_count / X_test_emotions_token_count\n",
    "print(\"Emotions test dataset hit rate\", X_test_emotions_hit_rate)\n",
    "\n",
    "X_train_sentiments_hit_rate = X_train_sentiments_hit_count / X_train_sentiments_token_count\n",
    "print(\"Sentiments test dataset hit rate\", X_train_sentiments_hit_rate)\n",
    "\n",
    "X_test_sentiments_hit_rate = X_test_sentiments_hit_count / X_test_sentiments_token_count\n",
    "print(\"Sentiments test dataset hit rate\", X_test_sentiments_hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e672857",
   "metadata": {},
   "source": [
    "### 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "40165e62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MLP emotions with embeddings with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1026   32   12   11   45    5    0   10    5    1    9    5    2   11\n",
      "     4   67    1   45  107    0  626   27    5    0    2    2    7   18]\n",
      " [  67  503   15   21   10    2    6    6    1    0    6    4    1    4\n",
      "     0   16    0   44   23    0  476    5    0    1    0    4    8    9]\n",
      " [  13   15  236   77    2    2    6    7    3    4   22   25    2    0\n",
      "     9    6    0    1    5    1  566    6    0    0    0    4    7    6]\n",
      " [  32   36  138  136   17    3   13   20    5   13   43   26    9    0\n",
      "     3   22    1    5   20    5 1136    4    0    0    1    5   16   11]\n",
      " [ 165   43   22   27  154   18   16   12   11    8   42   14    1    4\n",
      "     6   22    1   26   48    2 1641   25    3    0    4   11    9    6]\n",
      " [  22    5    9    9    9   77    1    8    5    2    9    1    0    3\n",
      "     2   22    0   13   10    3  460   29    0    0    0   18   16    1]\n",
      " [  20   16   16    9    8    4   95   97    0    2   17    2    0    1\n",
      "     4    2    0    0    5    1  671    6    0    2    0    4    2    8]\n",
      " [  24   10   16    8    8    2   35  264    3    1    8    0    1    6\n",
      "     2    4    0    5   13    2  751    4    0    0    0    2    3   14]\n",
      " [  13    8    4    4    4    6    2    2   65    0    0    3    0    3\n",
      "     2    7    0    4    8    1  257   23    0    0    0    1    2    1]\n",
      " [  22   13   26   38   10    3    6    6    3   31   27   19    2    1\n",
      "     4    8    1    4   13    4  628    8    0    2    5    9   35    8]\n",
      " [  29   26   43   37   22    6   14    6    1   12  141   14    4    1\n",
      "     2   15    0    7   10    0 1049    2    0    1    0    9    6    5]\n",
      " [  11   11   42   34    7    0    2    4    2    8   15   88    6    1\n",
      "    11    3    0    0    6    0  354    2    0    0    0    2   15    2]\n",
      " [   4    9    7   23    5    1    4    1    0    3    8    5   33    0\n",
      "     1    3    0    0    4    1  172    1    0    1    0    6    7    2]\n",
      " [  79   17    8    5    4    1    1   12    4    0    4    0    0   61\n",
      "     3   17    0   34   19    0  323   16    1    0    0    0    2   16]\n",
      " [  12    5    5   11    3    0    5    1    1    1    4    8    1    0\n",
      "    94    1    0    1    2    3  204    5    0    0    0    1    8    2]\n",
      " [  88    7    0    1    6   11    1    3    3    0    1    0    1    3\n",
      "     0 1044    0   29    9    0  122   16    1    0    1   14    6    4]\n",
      " [   3    0    3    1    0    0    0    0    0    1    0    0    0    0\n",
      "     0    0    8    2    0    0   47    0    0    0    0    4    3    1]\n",
      " [ 101   82    3    9   19    9    2    8    5    3    2    1    0   23\n",
      "     3   37    0  171   63    0  331   14    0    1    2    2    5   13]\n",
      " [  74   10    3    3    7    2    1    6    0    1    0    0    0    1\n",
      "     1    4    0   17  650    0  204    5    0    0    0    0    1    1]\n",
      " [   1    0    6    7    2    2    3    0    0    1    1    4    0    0\n",
      "     4    2    0    1    1   13   88    2    0    0    0    1    3    1]\n",
      " [ 346  163  210  150  138   79   92  218   38   32  171   78   15   26\n",
      "    28   88    5   75  138   12 8582   73    6    6    7   33   66   63]\n",
      " [  51    8    2    9   11   24    0    3   16    1    9    1    1    2\n",
      "     1   29    0    4   16    0  499  185    0    0    0    2    1    4]\n",
      " [  20    2    1    1    2    0    0    0    0    1    2    0    0    0\n",
      "     1   10    0    3    1    0   76    2    8    0    0    0    0    1]\n",
      " [  28    9   13   15   20    2    5    7    0    3   19    5    2    1\n",
      "     6    8    1    8    9    1  723    6    0    9    0    9    8    7]\n",
      " [   8    5    1    1    6    5    0    0    0    0    1    0    0    0\n",
      "     1   14    0   12    1    1   91    3    0    0    2    1    2    0]\n",
      " [   5    2    1    6    2    1    2    2    1    4    5    0    3    1\n",
      "     1    7    3    0    1    0   98    1    0    0    1  128   21    1]\n",
      " [  13   16   15   26   11    7    5    2    4   26   17    8    3    1\n",
      "     2    7    2    5    9    6  404    8    0    0    0   51  140    3]\n",
      " [  44   14   12    7    6    1    4   28    0    2   12    5    1   15\n",
      "     4    3    1    6    2    0  388    4    0    0    1    0    4  133]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.44      0.49      0.47      2085\n",
      "     amusement       0.47      0.41      0.44      1232\n",
      "         anger       0.27      0.23      0.25      1025\n",
      "     annoyance       0.20      0.08      0.11      1720\n",
      "      approval       0.29      0.07      0.11      2341\n",
      "        caring       0.28      0.10      0.15       734\n",
      "     confusion       0.30      0.10      0.14       992\n",
      "     curiosity       0.36      0.22      0.28      1186\n",
      "        desire       0.37      0.15      0.22       420\n",
      "disappointment       0.19      0.03      0.06       936\n",
      "   disapproval       0.24      0.10      0.14      1462\n",
      "       disgust       0.28      0.14      0.19       626\n",
      " embarrassment       0.38      0.11      0.17       301\n",
      "    excitement       0.36      0.10      0.15       627\n",
      "          fear       0.47      0.25      0.33       378\n",
      "     gratitude       0.71      0.76      0.74      1371\n",
      "         grief       0.33      0.11      0.16        73\n",
      "           joy       0.33      0.19      0.24       909\n",
      "          love       0.54      0.66      0.60       991\n",
      "   nervousness       0.23      0.09      0.13       143\n",
      "       neutral       0.41      0.78      0.54     10938\n",
      "      optimism       0.38      0.21      0.27       879\n",
      "         pride       0.33      0.06      0.10       131\n",
      "   realization       0.39      0.01      0.02       924\n",
      "        relief       0.08      0.01      0.02       155\n",
      "       remorse       0.40      0.43      0.41       297\n",
      "       sadness       0.35      0.18      0.23       791\n",
      "      surprise       0.39      0.19      0.26       697\n",
      "\n",
      "      accuracy                           0.41     34364\n",
      "     macro avg       0.35      0.22      0.25     34364\n",
      "  weighted avg       0.37      0.41      0.35     34364\n",
      "\n",
      "\n",
      "Base-MLP sentiment swith embeddings with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1127  551 1685  472]\n",
      " [ 349 3951 2637  785]\n",
      " [ 799 1917 6496 1827]\n",
      " [ 339 1080 3337 7012]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.43      0.29      0.35      3835\n",
      "    negative       0.53      0.51      0.52      7722\n",
      "     neutral       0.46      0.59      0.52     11039\n",
      "    positive       0.69      0.60      0.64     11768\n",
      "\n",
      "    accuracy                           0.54     34364\n",
      "   macro avg       0.53      0.50      0.51     34364\n",
      "weighted avg       0.55      0.54      0.54     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Perceptron Classifier for both emotions and sentiments.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_emotions = MLPClassifier()\n",
    "#train MLP emotions model\n",
    "mlp_model_emotions = mlp_emotions.fit(X_train_emotions_embeddings, y_train_emotions)\n",
    "#test MLP emotions model\n",
    "mlp_predict_emotions = mlp_model_emotions.predict(X_test_emotions_embeddings)\n",
    "\n",
    "mlp_sentiments = MLPClassifier()\n",
    "#train MLP sentiments model\n",
    "mlp_model_sentiments = mlp_sentiments.fit(X_train_sentiments_embeddings, y_train_sentiments)\n",
    "#test MLP sentiments model\n",
    "mlp_predict_sentiments = mlp_model_sentiments.predict(X_test_sentiments_embeddings)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mlp_predict_emotions, y_test_emotions, \"Base-MLP emotions with embeddings\", \"default parameters\")\n",
    "classification_performance(mlp_predict_sentiments, y_test_sentiments, \"Base-MLP sentiment swith embeddings\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ea533",
   "metadata": {},
   "source": [
    "### 3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a9465252",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-MLP emotions with embeddings with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  756    32     1     0     2     2     1     3     0     0     0     0\n",
      "      0     0     0    54     0     4    67     0  1162     1     0     0\n",
      "      0     0     0     0]\n",
      " [   54   257     2     2     0     0     0     1     0     0     1     1\n",
      "      0     0     0    16     0     2     9     0   886     1     0     0\n",
      "      0     0     0     0]\n",
      " [    3    20    85     9     0     1     0     3     0     0     3     5\n",
      "      0     0     0     5     0     0    16     0   872     0     0     0\n",
      "      0     0     3     0]\n",
      " [   11    39    32     8     0     0     3     2     0     0     6    10\n",
      "      0     0     0    17     0     0    14     0  1568     0     0     0\n",
      "      0     1     9     0]\n",
      " [  113    25     9     2     1     4     0     0     0     0     8     0\n",
      "      0     0     0    33     0     0    29     0  2110     7     0     0\n",
      "      0     0     0     0]\n",
      " [   15     1     1     2     0    17     0     2     0     0     0     0\n",
      "      0     0     0    52     0     1     5     0   625     3     0     0\n",
      "      0     4     6     0]\n",
      " [    8    11     3     1     0     1     5    11     0     0     3     2\n",
      "      0     0     0     2     0     0     2     0   938     0     0     0\n",
      "      0     1     4     0]\n",
      " [   10     7     1     0     0     1     3    19     0     0     1     0\n",
      "      0     0     0     4     0     0     4     0  1132     2     0     0\n",
      "      0     0     2     0]\n",
      " [    7     3     1     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0    16     0     3    16     0   363     9     0     0\n",
      "      0     0     1     0]\n",
      " [   12    13     5     5     0     0     1     0     0     0     9     4\n",
      "      0     0     0     4     0     0     6     0   858     0     0     0\n",
      "      0     4    15     0]\n",
      " [   16    14     9     7     0     0     0     4     0     0    16     3\n",
      "      0     0     0     4     0     1     7     0  1376     1     0     0\n",
      "      0     2     2     0]\n",
      " [   12    19    19     9     0     0     0     0     0     0     5    25\n",
      "      0     0     0     0     0     0     3     0   529     0     0     0\n",
      "      0     0     5     0]\n",
      " [    5     7     6     3     0     0     4     0     0     0     0     1\n",
      "      0     0     0     3     0     0     2     0   265     0     0     0\n",
      "      0     0     5     0]\n",
      " [   79    13     7     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0    30     0    21    12     0   464     0     0     0\n",
      "      0     0     0     0]\n",
      " [    6     5     4     3     0     1     0     0     0     0     1    11\n",
      "      0     0     1     0     0     0     1     0   336     0     0     0\n",
      "      0     0     9     0]\n",
      " [   70     6     1     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0   953     0     5     4     0   330     1     0     0\n",
      "      0     0     0     0]\n",
      " [    1     3     0     1     0     1     0     0     0     0     1     0\n",
      "      0     0     0     7     0     0     0     0    59     0     0     0\n",
      "      0     0     0     0]\n",
      " [  119    42     2     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0    68     0    28    43     0   603     1     0     0\n",
      "      0     0     2     0]\n",
      " [   51     9     1     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0     6     0     1   440     0   482     0     0     0\n",
      "      0     0     0     0]\n",
      " [    2     1     1     1     0     0     0     0     0     0     2     0\n",
      "      0     0     0     1     0     0     0     0   131     0     0     0\n",
      "      0     0     4     0]\n",
      " [  252   136    77    16     2     7     5    41     0     1    31    13\n",
      "      0     0     2   119     0    17    90     0 10097     4     0     0\n",
      "      0     8    20     0]\n",
      " [   41     0     0     0     0     3     0     0     0     0     0     0\n",
      "      0     0     0    57     0     0    14     0   745    18     0     0\n",
      "      0     1     0     0]\n",
      " [   18     0     1     0     0     1     0     0     0     0     1     0\n",
      "      0     0     0    10     0     0     1     0    98     1     0     0\n",
      "      0     0     0     0]\n",
      " [   21    11     2     0     0     1     1     0     0     0     5     0\n",
      "      0     0     0     6     0     1     2     0   870     0     0     0\n",
      "      0     0     4     0]\n",
      " [    5     2     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    10     0     0     0     0   137     0     0     0\n",
      "      0     0     0     0]\n",
      " [    2     9     1     1     0     0     0     0     0     0     2     1\n",
      "      0     0     0    10     0     0     3     0   227     0     0     0\n",
      "      0    34     7     0]\n",
      " [   11    24     8     4     0     2     0     1     0     2     7     4\n",
      "      0     0     1     8     0     0     9     0   659     1     0     0\n",
      "      0    15    35     0]\n",
      " [   41    32     7     1     0     0     3     5     0     0     1     1\n",
      "      0     0     1     9     0     3     8     0   580     0     0     0\n",
      "      0     0     4     1]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.43      0.36      0.40      2085\n",
      "     amusement       0.35      0.21      0.26      1232\n",
      "         anger       0.30      0.08      0.13      1025\n",
      "     annoyance       0.11      0.00      0.01      1720\n",
      "      approval       0.20      0.00      0.00      2341\n",
      "        caring       0.37      0.02      0.04       734\n",
      "     confusion       0.19      0.01      0.01       992\n",
      "     curiosity       0.21      0.02      0.03      1186\n",
      "        desire       0.00      0.00      0.00       420\n",
      "disappointment       0.00      0.00      0.00       936\n",
      "   disapproval       0.16      0.01      0.02      1462\n",
      "       disgust       0.31      0.04      0.07       626\n",
      " embarrassment       0.00      0.00      0.00       301\n",
      "    excitement       0.00      0.00      0.00       627\n",
      "          fear       0.20      0.00      0.01       378\n",
      "     gratitude       0.63      0.70      0.66      1371\n",
      "         grief       0.00      0.00      0.00        73\n",
      "           joy       0.32      0.03      0.06       909\n",
      "          love       0.55      0.44      0.49       991\n",
      "   nervousness       0.00      0.00      0.00       143\n",
      "       neutral       0.35      0.92      0.51     10938\n",
      "      optimism       0.36      0.02      0.04       879\n",
      "         pride       0.00      0.00      0.00       131\n",
      "   realization       0.00      0.00      0.00       924\n",
      "        relief       0.00      0.00      0.00       155\n",
      "       remorse       0.49      0.11      0.19       297\n",
      "       sadness       0.26      0.04      0.08       791\n",
      "      surprise       1.00      0.00      0.00       697\n",
      "\n",
      "      accuracy                           0.37     34364\n",
      "     macro avg       0.24      0.11      0.11     34364\n",
      "  weighted avg       0.30      0.37      0.25     34364\n",
      "\n",
      "\n",
      "Top-MLP sentiment swith embeddings with activation: sigmoid, tanh, relu, identity, solver: adam and sgd:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 482  824 1490 1039]\n",
      " [ 153 4145 1992 1432]\n",
      " [ 352 2495 5177 3015]\n",
      " [ 122 1467 2160 8019]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.43      0.13      0.19      3835\n",
      "    negative       0.46      0.54      0.50      7722\n",
      "     neutral       0.48      0.47      0.47     11039\n",
      "    positive       0.59      0.68      0.63     11768\n",
      "\n",
      "    accuracy                           0.52     34364\n",
      "   macro avg       0.49      0.45      0.45     34364\n",
      "weighted avg       0.51      0.52      0.50     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_space_Top_MLP_emb = {\n",
    "    'activation' : np.array(['identity', 'logistic', 'tanh', 'relu']),\n",
    "    'hidden_layer_sizes' : [(30, 50), (10, 10, 10)],\n",
    "    'solver' : ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "GS_MLP_emotions = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP_emb)\n",
    "#train GS MLP emotions model\n",
    "GS_MLP_model_emotions = GS_MLP_emotions.fit(X_train_emotions_embeddings, y_train_emotions)\n",
    "#test GS MLP emotions model\n",
    "GS_MLP_predict_emotions = GS_MLP_model_emotions.predict(X_test_emotions_embeddings)\n",
    "\n",
    "GS_MLP_sentiments = GridSearchCV(MLPClassifier(max_iter=1), search_space_Top_MLP_emb)\n",
    "#train GS MLP sentiments model\n",
    "GS_MLP_model_sentiments = GS_MLP_sentiments.fit(X_train_sentiments_embeddings, y_train_sentiments)\n",
    "#test GS MLP sentiments model\n",
    "GS_MLP_predict_sentiments = GS_MLP_model_sentiments.predict(X_test_sentiments_embeddings)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(GS_MLP_predict_emotions, y_test_emotions, \"Top-MLP emotions with embeddings\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")\n",
    "classification_performance(GS_MLP_predict_sentiments, y_test_sentiments, \"Top-MLP sentiment swith embeddings\", \"activation: sigmoid, tanh, relu, identity, solver: adam and sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e82316",
   "metadata": {},
   "source": [
    "### 3.7 as seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ccbbcb",
   "metadata": {},
   "source": [
    "### 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a1bd6",
   "metadata": {},
   "source": [
    "### 3.8.1 (using Base-MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dada1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model loaded!\n"
     ]
    }
   ],
   "source": [
    "wv_model_gigaword = api.load(\"glove-wiki-gigaword-100\")\n",
    "print(\"New Model loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ed763",
   "metadata": {},
   "source": [
    "### 3.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "11dfeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2  Use the tokenizer from nltk to extract words from the Reddit posts. Display the number\n",
    "# of tokens in the training set.\n",
    "\n",
    "def comment_tokenizer(comments):\n",
    "    tokenized_comments = []\n",
    "\n",
    "    for comment in comments:\n",
    "        token_comment = word_tokenize(comment)\n",
    "        tokenized_comments.append(token_comment)\n",
    "    return tokenized_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6119bea",
   "metadata": {},
   "source": [
    "### 3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cd506eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Compute the embedding of a Reddit post as the average of the embeddings of its words. If\n",
    "# a word has no embedding in Word2Vec, skip it.\n",
    "\n",
    "def embedded_comments(tokenized_comments):\n",
    "    comment_embeddings = []\n",
    "    hit_count = 0\n",
    "    token_count = 0\n",
    "    \n",
    "    for comment in tokenized_comments:\n",
    "        comment_token_embeddings = []\n",
    "        for token in comment:\n",
    "            token_count += 1\n",
    "            try:\n",
    "                embedded_token = wv_model_gigaword[token]\n",
    "                comment_token_embeddings.append(embedded_token)\n",
    "                hit_count += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if len(comment_token_embeddings) != 0: \n",
    "            tkn_embdng = np.array(comment_token_embeddings)\n",
    "            comment_embeddings.append(np.mean(tkn_embdng, axis=0))\n",
    "        else:\n",
    "            comment_embeddings.append(np.zeros(100))\n",
    "    return comment_embeddings, hit_count, token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2efdb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split dataset for emotions classification\n",
    "X_train_emotions, X_test_emotions, y_train_emotions, y_test_emotions = train_test_split(comments,y_emotions, test_size=0.2)\n",
    "\n",
    "#split dataset for sentiments classification\n",
    "X_train_sentiments, X_test_sentiments, y_train_sentiments, y_test_sentiments = train_test_split(comments,y_sentiments, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "55fafa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_X_train_emotions = comment_tokenizer(X_train_emotions)\n",
    "tokenized_X_test_emotions = comment_tokenizer(X_test_emotions)\n",
    "tokenized_X_train_sentiments = comment_tokenizer(X_train_sentiments)\n",
    "tokenized_X_test_sentiments = comment_tokenizer(X_test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c5429f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emotions_embeddings, X_train_emotions_hit_count, X_train_emotions_token_count = embedded_comments(tokenized_X_train_emotions)\n",
    "X_test_emotions_embeddings, X_test_emotions_hit_count, X_test_emotions_token_count = embedded_comments(tokenized_X_test_emotions)\n",
    "X_train_sentiments_embeddings, X_train_sentiments_hit_count, X_train_sentiments_token_count = embedded_comments(tokenized_X_train_sentiments)\n",
    "X_test_sentiments_embeddings, X_test_sentiments_hit_count, X_test_sentiments_token_count = embedded_comments(tokenized_X_test_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4336f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the training set: 2114004\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in the training set: \"+ str(X_train_emotions_token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee3fb2",
   "metadata": {},
   "source": [
    "### 3.8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8f909958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions training dataset hit rate 0.8536365115676224\n",
      "Emotions test dataset hit rate 0.852619839280169\n",
      "Sentiments test dataset hit rate 0.8536086802949984\n",
      "Sentiments test dataset hit rate 0.8527298210211486\n"
     ]
    }
   ],
   "source": [
    "X_train_emotions_hit_rate = X_train_emotions_hit_count / X_train_emotions_token_count\n",
    "print(\"Emotions training dataset hit rate\", X_train_emotions_hit_rate)\n",
    "\n",
    "X_test_emotions_hit_rate = X_test_emotions_hit_count / X_test_emotions_token_count\n",
    "print(\"Emotions test dataset hit rate\", X_test_emotions_hit_rate)\n",
    "\n",
    "X_train_sentiments_hit_rate = X_train_sentiments_hit_count / X_train_sentiments_token_count\n",
    "print(\"Sentiments test dataset hit rate\", X_train_sentiments_hit_rate)\n",
    "\n",
    "X_test_sentiments_hit_rate = X_test_sentiments_hit_count / X_test_sentiments_token_count\n",
    "print(\"Sentiments test dataset hit rate\", X_test_sentiments_hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8555f",
   "metadata": {},
   "source": [
    "### 3.8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "43679581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/michaeldjabauri/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-MLP emotions with embeddings with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 789   23    7    6    5    1    0    5    0    1    4    3    1   14\n",
      "     2   65    0   18   75    0 1044   25    4    0    0    1    4    2]\n",
      " [  68  351   11   20    3    0    2    8    1    4    6    2    0    1\n",
      "     1   13    0   21   17    0  747    7    0    0    0    7    7    1]\n",
      " [  15   14  114   56    0    1    1   10    1    4    5    9    0    0\n",
      "     7    8    0    1    8    0  733    1    0    0    0    4   12    0]\n",
      " [  32   31   51   71    0    7    1    7    4    6   30   13    1    2\n",
      "     5   11    0    7   12    0 1280    1    0    0    0   10   28    2]\n",
      " [ 140   30    8   20   31    7    3   13    2    1   24    5    0    6\n",
      "     1   51    0   14   42    0 1892   15    0    0    0    8   16    3]\n",
      " [  25    4    3    3    3   38    0    1    1    0    7    0    0    0\n",
      "     1   46    0    6   13    0  489   28    0    0    0    7   13    0]\n",
      " [  14    6    5    8    3    1    7   87    1    1    8    0    0    3\n",
      "     1    4    0    0    8    0  799    2    0    0    0    7    3    3]\n",
      " [  29    7    6    7    3    3    5  178    1    0    5    0    1    2\n",
      "     0    8    0    1    6    0  889    5    0    0    0    1    2    3]\n",
      " [  14    3    2    0    1    1    0    1   24    1    2    0    0    0\n",
      "     0   12    0    5   11    0  328    9    0    0    0    1    3    0]\n",
      " [  29   11   12   12    1    3    0    7    2   15   20    8    1    0\n",
      "     2   10    0    3   10    3  729    4    0    0    0    8   37    3]\n",
      " [  33   20   22   28    4    5    0    8    0    8   57    3    0    1\n",
      "     3   21    0    2   15    0 1325    8    0    0    0   14   13    4]\n",
      " [  11    7   22   25    0    0    0    2    0    9   11   49    0    0\n",
      "     9    3    0    1    0    0  420    1    0    0    0    2   11    0]\n",
      " [   5    9    5    6    0    0    0    1    1    1    6    1    5    0\n",
      "     0    0    0    2    2    0  255    0    0    0    0    9    5    0]\n",
      " [  56   15    4    3    0    0    0    7    2    0    0    0    0   39\n",
      "     2   19    0   13   26    1  419    9    0    0    0    0    0    1]\n",
      " [   5    9    4    3    0    2    0    2    0    0    0    6    0    1\n",
      "    48    1    0    2    2    4  290    3    0    0    0    0    5    2]\n",
      " [  95   10    6    1    6    5    0    8    1    2    1    0    0    3\n",
      "     2  634    0   23   13    0  570   24    0    0    0   18    7    0]\n",
      " [   1    0    1    1    0    0    0    0    0    1    0    0    0    0\n",
      "     1    1    1    0    0    0   48    1    0    0    0    2    5    0]\n",
      " [  76   42    3    1    2    4    0    2    3    1    3    1    0    7\n",
      "     1   49    0   68   72    0  476   10    0    0    0    2    5    0]\n",
      " [  74    7    2    2    2    0    0    1    0    0    0    1    0    0\n",
      "     0   20    0   13  487    0  394    4    0    0    0    1    2    0]\n",
      " [   4    2    2    1    0    0    0    1    0    0    1    0    1    2\n",
      "     0    2    0    0    0    7  138    0    0    0    0    2    6    0]\n",
      " [ 314  124   95   67   22   32    8  178   14   13   84   15    2   21\n",
      "    13  142    4   41  132    2 9514   56    2    1    0   19   66   19]\n",
      " [  48    5    1    8    5   14    2    1    7    1    2    0    0    3\n",
      "     1   28    0   11   12    0  592  108    0    0    0    2    8    0]\n",
      " [  16    0    0    2    0    0    0    0    1    0    0    0    0    0\n",
      "     0    3    0    0    4    0   86    3    4    0    0    0    1    0]\n",
      " [  23    8    5   10    4    1    2    3    3    0   13    1    0    1\n",
      "     1    8    0    1    4    0  817    9    0    0    0    7   11    1]\n",
      " [   8    2    0    2    0    2    0    0    0    0    0    0    0    0\n",
      "     1    9    0    5    5    0  125    2    0    0    0    1    3    0]\n",
      " [   1    1    2    3    1    3    0    1    0    1    2    0    0    0\n",
      "     1   11    0    1    1    0  183    1    0    0    0   64   10    0]\n",
      " [   9    8    5    8    1    4    0    1    2   10    6    6    1    0\n",
      "     2   11    1    3   11    0  521    4    1    0    0   44  112    0]\n",
      " [  33    7   10    8    0    1    1   15    1    1    6    2    0    4\n",
      "     2   14    0    1    2    0  573    3    0    0    0    2    2   33]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.40      0.38      0.39      2099\n",
      "     amusement       0.46      0.27      0.34      1298\n",
      "         anger       0.28      0.11      0.16      1004\n",
      "     annoyance       0.19      0.04      0.07      1612\n",
      "      approval       0.32      0.01      0.03      2332\n",
      "        caring       0.28      0.06      0.09       688\n",
      "     confusion       0.22      0.01      0.01       971\n",
      "     curiosity       0.32      0.15      0.21      1162\n",
      "        desire       0.33      0.06      0.10       418\n",
      "disappointment       0.19      0.02      0.03       930\n",
      "   disapproval       0.19      0.04      0.06      1594\n",
      "       disgust       0.39      0.08      0.14       583\n",
      " embarrassment       0.38      0.02      0.03       313\n",
      "    excitement       0.35      0.06      0.11       616\n",
      "          fear       0.45      0.12      0.19       389\n",
      "     gratitude       0.53      0.44      0.48      1429\n",
      "         grief       0.17      0.02      0.03        63\n",
      "           joy       0.26      0.08      0.12       828\n",
      "          love       0.49      0.48      0.49      1010\n",
      "   nervousness       0.41      0.04      0.08       169\n",
      "       neutral       0.37      0.86      0.52     11000\n",
      "      optimism       0.31      0.13      0.18       859\n",
      "         pride       0.36      0.03      0.06       120\n",
      "   realization       0.00      0.00      0.00       933\n",
      "        relief       0.00      0.00      0.00       165\n",
      "       remorse       0.26      0.22      0.24       287\n",
      "       sadness       0.28      0.15      0.19       771\n",
      "      surprise       0.43      0.05      0.08       721\n",
      "\n",
      "      accuracy                           0.37     34364\n",
      "     macro avg       0.31      0.14      0.16     34364\n",
      "  weighted avg       0.33      0.37      0.28     34364\n",
      "\n",
      "\n",
      "Base-MLP sentiment swith embeddings with default parameters:\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 651  532 1606 1017]\n",
      " [ 206 3047 2563 1919]\n",
      " [ 473 1585 5451 3545]\n",
      " [ 203  939 2800 7827]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.42      0.17      0.24      3806\n",
      "    negative       0.50      0.39      0.44      7735\n",
      "     neutral       0.44      0.49      0.46     11054\n",
      "    positive       0.55      0.67      0.60     11769\n",
      "\n",
      "    accuracy                           0.49     34364\n",
      "   macro avg       0.48      0.43      0.44     34364\n",
      "weighted avg       0.49      0.49      0.48     34364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default Parameter Perceptron Classifier for both emotions and sentiments.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_emotions = MLPClassifier()\n",
    "#train MLP emotions model\n",
    "mlp_model_emotions = mlp_emotions.fit(X_train_emotions_embeddings, y_train_emotions)\n",
    "#test MLP emotions model\n",
    "mlp_predict_emotions = mlp_model_emotions.predict(X_test_emotions_embeddings)\n",
    "\n",
    "mlp_sentiments = MLPClassifier()\n",
    "#train MLP sentiments model\n",
    "mlp_model_sentiments = mlp_sentiments.fit(X_train_sentiments_embeddings, y_train_sentiments)\n",
    "#test MLP sentiments model\n",
    "mlp_predict_sentiments = mlp_model_sentiments.predict(X_test_sentiments_embeddings)\n",
    "\n",
    "#write confusion matrix, precision, recall and f1-measure to text file for both emotions and sentiments.\n",
    "classification_performance(mlp_predict_emotions, y_test_emotions, \"Base-MLP emotions with embeddings\", \"default parameters\")\n",
    "classification_performance(mlp_predict_sentiments, y_test_sentiments, \"Base-MLP sentiment swith embeddings\", \"default parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cd81a",
   "metadata": {},
   "source": [
    "### 3.8.7 As seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cec38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
